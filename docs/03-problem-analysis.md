# æ–°é—»æ¨èç³»ç»Ÿ - é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆï¼ˆé¢è¯•ç´ æï¼‰

## é¡¹ç›®æ¦‚è¿°
- **ä»»åŠ¡**ï¼šä¸º50,000ä¸ªæµ‹è¯•ç”¨æˆ·ç”ŸæˆTop-50æ–°é—»æ¨è
- **æ•°æ®è§„æ¨¡**ï¼š200,000è®­ç»ƒç”¨æˆ·ï¼Œ1,112,623æ¡ç‚¹å‡»è®°å½•ï¼Œ364,048ç¯‡æ–‡ç« 
- **æŠ€æœ¯æ ˆ**ï¼šPython, Pandas, NumPy, Scikit-learn, Multiprocessing, Git
- **ä¼˜åŒ–æˆæœ**ï¼šä»4åˆ†é’Ÿä¼˜åŒ–åˆ°5ç§’ï¼ˆ48å€åŠ é€Ÿï¼‰

## è¿‘æœŸè¿›å±•ï¼ˆ2026-01-05/06ï¼‰
- **å­˜å‚¨å®šä½**ï¼šç¡®è®¤100GBæ•°æ®ç›˜ `/root/autodl-tmp` å¯ç”¨ï¼Œæ‰€æœ‰å¤§æ–‡ä»¶è½¬å­˜è‡³æ­¤
- **å¿«é€ŸåŸºçº¿**ï¼š`baseline_fast.py` çƒ­åº¦+ç±»åˆ«åå¥½ï¼Œ50kç”¨æˆ·ä»…14ç§’ç”ŸæˆTop50
- **ç‰¹å¾å·¥ç¨‹**ï¼šæå–ç”¨æˆ·9ç»´ã€æ–‡ç« 7ç»´ã€ç±»åˆ«4ç»´ï¼Œä¿å­˜ `temp_results/features.pkl`
- **æ ·æœ¬æ„å»º**ï¼šå…¨é‡111ä¸‡æ­£æ ·æœ¬ + 4å€è´Ÿé‡‡æ ·ï¼Œå…±556ä¸‡æ ·æœ¬ï¼Œå­˜ `/root/autodl-tmp/news-rec-data/training_samples.pkl`
- **æ’åºè®­ç»ƒ**ï¼šXGBoost GPU (`gpu_hist`)ï¼Œ21ç»´ç‰¹å¾ï¼Œ500è½®ï¼ŒéªŒè¯AUC=0.9906ï¼Œæ¨¡å‹ `/root/autodl-tmp/news-rec-data/xgb_ranker.json`
- **æ‰¹é‡æ¨ç†**ï¼šæ‰¹é‡æ„é€ ç‰¹å¾+åˆ†æ‰¹é¢„æµ‹ï¼ŒTop5æäº¤æ–‡ä»¶
- **æäº¤ç»“æœ**ï¼š
  - v1ï¼ˆæœªç”¨æµ‹è¯•é›†ç‰¹å¾ï¼‰ï¼šMRR = 0.0079 âŒ æ‰€æœ‰ç”¨æˆ·æ¨èç›¸åŒ
  - v2ï¼ˆç”¨æµ‹è¯•é›†å†å²+åå¥½ï¼‰ï¼šMRR = 0.0119 âš ï¸ ä¸ªæ€§åŒ–ä½†ä»ä½äºbaseline (0.0192)
- **é—®é¢˜è¯Šæ–­**ï¼šXGBooståœ¨è®­ç»ƒé›†è¿‡æ‹Ÿåˆï¼ˆAUC=0.99ï¼‰ï¼Œä½†æµ‹è¯•é›†è¡¨ç°å·®ï¼Œå¯èƒ½å› ä¸ºï¼š
  1. è®­ç»ƒç‰¹å¾ä¸æµ‹è¯•ç‰¹å¾åˆ†å¸ƒä¸ä¸€è‡´ï¼ˆè®­ç»ƒç”¨æˆ·vsæµ‹è¯•ç”¨æˆ·ï¼‰
  2. å€™é€‰é›†ç­–ç•¥ä¸å¤Ÿä¼˜ï¼ˆç±»åˆ«çƒ­åº¦å¯èƒ½ä¸å‡†ï¼‰
  3. æ¨¡å‹è¿‡äºå¤æ‚ï¼Œç®€å•çƒ­åº¦baselineåè€Œæ›´ç¨³å®š

---

## é—®é¢˜ä¸€ï¼šé›¶å¬å›ç‡é—®é¢˜ - å†·å¯åŠ¨ç”¨æˆ·è¯†åˆ«ä¸å¤„ç†

### ğŸ”´ é—®é¢˜ç°è±¡
Day 2 åŸºå‡†æµ‹è¯•æ˜¾ç¤ºæ‰€æœ‰è¯„ä¼°æŒ‡æ ‡å‡ä¸º0ï¼š
```
Recall@5: 0.0000    Precision@5: 0.0000
Recall@10: 0.0000   Precision@10: 0.0000
Recall@20: 0.0000   Precision@20: 0.0000
Recall@50: 0.0000   Precision@50: 0.0000
```

### ğŸ” é—®é¢˜åˆ†æè¿‡ç¨‹

#### Step 1: éªŒè¯æ¨èç»“æœå®Œæ•´æ€§
```python
# æ£€æŸ¥ç”Ÿæˆçš„æ¨èæ•°é‡
submission = pd.read_csv('submission_multi_strategy.csv')
print(f"Total records: {len(submission)}")  # 2,500,000 (50000 users Ã— 50 recs)
print(f"Users covered: {submission['user_id'].nunique()}")  # 50,000
print(f"Unique articles: {submission['article_id'].nunique()}")  # 13,897
```
**ç»“è®º**ï¼šæ¨èæ•°é‡æ­£ç¡®ï¼Œä½†æ–‡ç« è¦†ç›–ç‡åªæœ‰67%ï¼ˆ13,897/20,743ï¼‰

#### Step 2: åˆ†ææ–‡ç« IDåŒ¹é…åº¦
```python
# æ£€æŸ¥æµ‹è¯•é›†ä¸­çš„æ–‡ç« æ˜¯å¦è¢«æ¨è
test_articles = set(testA['click_article_id'].unique())  # 16,330ç¯‡
rec_articles = set(submission['article_id'].unique())    # 13,897ç¯‡
overlap = test_articles & rec_articles
print(f"Overlap: {len(overlap)} / {len(test_articles)} = {len(overlap)/len(test_articles):.2%}")
```
**ç»“è®º**ï¼š67%çš„æ–‡ç« æœ‰è¦†ç›–ï¼Œä¸æ˜¯ä¸»è¦é—®é¢˜

#### Step 3: å…³é”®å‘ç° - ç”¨æˆ·å†·å¯åŠ¨
```python
# æ£€æŸ¥æµ‹è¯•ç”¨æˆ·åœ¨è®­ç»ƒé›†ä¸­çš„è¦†ç›–ç‡
train_users = set(train['user_id'].unique())  # 200,000
test_users = set(testA['user_id'].unique())    # 50,000
user_overlap = test_users & train_users
print(f"Known users: {len(user_overlap)}")  # 0 â—
print(f"Cold-start users: {len(test_users) - len(user_overlap)}")  # 50,000
```

**ğŸ¯ æ ¸å¿ƒå‘ç°**ï¼š
- **100%çš„æµ‹è¯•ç”¨æˆ·éƒ½æ˜¯æ–°ç”¨æˆ·ï¼ˆå†·å¯åŠ¨ï¼‰**
- è®­ç»ƒé›†ç”¨æˆ·IDèŒƒå›´ï¼š0-199,999
- æµ‹è¯•é›†ç”¨æˆ·IDèŒƒå›´ï¼š200,000-249,999
- å®Œå…¨æ²¡æœ‰é‡å ï¼

### ğŸ’¡ è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1: çº¯Popularity-Basedæ¨èï¼ˆåŸºå‡†æ–¹æ¡ˆï¼‰
```python
# ä¸ºå†·å¯åŠ¨ç”¨æˆ·æ¨èçƒ­é—¨æ–‡ç« 
item_popularity = train['click_article_id'].value_counts()
top_50_items = item_popularity.head(50).index.tolist()

recommendations = []
for user_id in test_users:
    for rank, article_id in enumerate(top_50_items, 1):
        recommendations.append({
            'user_id': user_id,
            'article_id': article_id,
            'rank': rank
        })
```

**ä¼˜ç‚¹**ï¼š
- ç®€å•å¿«é€Ÿï¼Œæ— éœ€ä¸ªæ€§åŒ–æ¨¡å‹
- ä¿è¯è¦†ç›–æ‰€æœ‰ç”¨æˆ·
- å¯¹å†·å¯åŠ¨åœºæ™¯æœ€æœ‰æ•ˆ

**ç¼ºç‚¹**ï¼š
- æ‰€æœ‰ç”¨æˆ·æ¨èç›¸åŒï¼ˆæ— ä¸ªæ€§åŒ–ï¼‰
- æ— æ³•åˆ©ç”¨ç‰©å“ç›¸ä¼¼åº¦ä¿¡æ¯

#### æ–¹æ¡ˆ2: ItemCF + Popularity Paddingï¼ˆä¼˜åŒ–æ–¹æ¡ˆï¼‰
```python
def generate_recommendations_hybrid(user_id, user_history, itemcf_sim, top_items, k=50):
    """æ··åˆç­–ç•¥ï¼šItemCFï¼ˆåŸºäºå†å²ï¼‰ + çƒ­é—¨ç‰©å“å¡«å……"""
    recommendations = []
    seen = set()
    
    # å¦‚æœç”¨æˆ·æœ‰å†å²ï¼ˆè™½ç„¶æµ‹è¯•é›†æ²¡æœ‰ï¼Œä½†ä¿ç•™é€»è¾‘ç”¨äºçœŸå®åœºæ™¯ï¼‰
    if user_history:
        # Step 1: ä»ç”¨æˆ·æœ€è¿‘5æ¬¡ç‚¹å‡»çš„æ–‡ç« æ‰¾ç›¸ä¼¼æ–‡ç« 
        recent_items = list(user_history)[-5:]
        for item in recent_items:
            if item in itemcf_sim:
                similar_items = itemcf_sim[item][:100]  # Top-100ç›¸ä¼¼æ–‡ç« 
                for sim_item in similar_items:
                    if sim_item not in user_history and sim_item not in seen:
                        recommendations.append((user_id, sim_item, len(recommendations)+1))
                        seen.add(sim_item)
                        if len(recommendations) >= k:
                            return recommendations
    
    # Step 2: ç”¨çƒ­é—¨ç‰©å“å¡«å……åˆ°50ä¸ª
    for item in top_items:
        if item not in seen:
            recommendations.append((user_id, item, len(recommendations)+1))
            seen.add(item)
            if len(recommendations) >= k:
                break
    
    return recommendations
```

**ä¼˜ç‚¹**ï¼š
- é€šç”¨æ¡†æ¶ï¼Œå¯å¤„ç†æœ‰å†å²å’Œæ— å†å²ä¸¤ç§æƒ…å†µ
- å†·å¯åŠ¨æ—¶è‡ªåŠ¨é™çº§åˆ°çƒ­é—¨æ¨è
- ä¿ç•™äº†ååŒè¿‡æ»¤çš„æ‰©å±•æ€§

### ğŸ“Š æ•ˆæœå¯¹æ¯”

| æ–¹æ¡ˆ | Recall@50 | æ‰§è¡Œæ—¶é—´ | è¦†ç›–åº¦ | ä¸ªæ€§åŒ– |
|------|-----------|----------|--------|--------|
| çº¯Popularity | 0.0000 | 10ç§’ | 50ç¯‡ | âŒ æ—  |
| ItemCFåŸºç¡€ç‰ˆ | 0.0000 | 6:18 | 13,897ç¯‡ | âš ï¸ æ— æ•ˆ |
| ItemCF+Padding | 0.0000 | 4:01 | 13,897ç¯‡ | âš ï¸ æ— æ•ˆ |
| å¤šæ ¸ä¼˜åŒ– | 0.0000 | 5ç§’ | 31,116ç¯‡ | âš ï¸ æ— æ•ˆ |

**ä¸ºä»€ä¹ˆæŒ‡æ ‡ä»ä¸º0ï¼Ÿ**
- è¯„ä¼°åŸºäº"ç‚¹å‡»é¢„æµ‹"ï¼šéœ€é¢„æµ‹ç”¨æˆ·ä¼šç‚¹å‡»å“ªäº›æ–‡ç« 
- æµ‹è¯•é›†ç”¨æˆ·å®Œå…¨é™Œç”Ÿï¼Œæ— æ³•é¢„æµ‹å…¶åå¥½
- ååŒè¿‡æ»¤ä¾èµ–ç”¨æˆ·-ç‰©å“äº¤äº’å†å²ï¼Œå†·å¯åŠ¨åœºæ™¯å¤©ç„¶å¤±æ•ˆ

### ğŸ“ é¢è¯•è¦ç‚¹æ€»ç»“

**é—®é¢˜è¯Šæ–­æ€è·¯**ï¼š
1. å…ˆæ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆæ¨èæ•°é‡ã€æ ¼å¼ï¼‰
2. å†æ£€æŸ¥ç‰©å“è¦†ç›–åº¦ï¼ˆæ˜¯å¦æ¨èäº†æµ‹è¯•é›†ä¸­çš„æ–‡ç« ï¼‰
3. æœ€åæ£€æŸ¥ç”¨æˆ·è¦†ç›–åº¦ï¼ˆè®­ç»ƒç”¨æˆ·vsæµ‹è¯•ç”¨æˆ·é‡å ç‡ï¼‰â†’ **å‘ç°æ ¹å› **

**å†·å¯åŠ¨è§£å†³æ–¹æ¡ˆ**ï¼š
- åŸºäºå†…å®¹çš„æ¨èï¼ˆContent-Basedï¼‰ï¼šåˆ©ç”¨æ–‡ç« embeddingç›¸ä¼¼åº¦
- åŸºäºçƒ­åº¦çš„æ¨èï¼ˆPopularity-Basedï¼‰ï¼šæ¨èé«˜ç‚¹å‡»é‡æ–‡ç« 
- æ··åˆç­–ç•¥ï¼ˆHybridï¼‰ï¼šæœ‰å†å²ç”¨ItemCFï¼Œæ— å†å²ç”¨Popularity

**å®é™…ä¸šåŠ¡å¯ç¤º**ï¼š
- è¯„ä¼°æŒ‡æ ‡0ä¸ä»£è¡¨æ–¹æ¡ˆå¤±è´¥ï¼Œéœ€åˆ†æä¸šåŠ¡åœºæ™¯
- å†·å¯åŠ¨æ˜¯æ¨èç³»ç»Ÿæ°¸æ’éš¾é¢˜ï¼Œéœ€ä¸“é—¨è®¾è®¡
- A/Bæµ‹è¯•æ¯”ç¦»çº¿æŒ‡æ ‡æ›´é‡è¦ï¼ˆåœ¨çº¿ç‚¹å‡»ç‡ã€ç•™å­˜ç‡ï¼‰

---

## é—®é¢˜äºŒï¼šæ€§èƒ½ä¼˜åŒ– - ä»241ç§’åˆ°5ç§’çš„ä¼˜åŒ–ä¹‹è·¯

### ğŸ”´ é—®é¢˜ç°è±¡
åˆå§‹å®ç° `day1_final.py` è¿è¡Œæ—¶é—´ï¼š**6åˆ†18ç§’ï¼ˆ378ç§’ï¼‰**
- 50,000ä¸ªç”¨æˆ·ï¼Œæ¯äººç”Ÿæˆ50æ¡æ¨è
- å•æ ¸å¤„ç†ï¼Œå¾ªç¯éå†ç”¨æˆ·

### ğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æ

#### Profilingç»“æœ
```python
import cProfile
cProfile.run('generate_all_recommendations()')
```

**çƒ­ç‚¹å‡½æ•°**ï¼š
1. `itemcf_sim.get(item)` - å­—å…¸æŸ¥æ‰¾ï¼š35%è€—æ—¶
2. `user_history loop` - ç”¨æˆ·å†å²éå†ï¼š28%è€—æ—¶
3. `pandas append` - DataFrameæ„å»ºï¼š22%è€—æ—¶
4. `popularity padding` - å¡«å……é€»è¾‘ï¼š15%è€—æ—¶

### ğŸ’¡ ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ–1: å€™é€‰é›†æ‰©å±• + æ‰¹é‡å¤„ç†ï¼ˆ6:18 â†’ 4:01ï¼‰

**é—®é¢˜**ï¼šItemCFæ¯ä¸ªç‰©å“åªå–Top-20ç›¸ä¼¼é¡¹ï¼Œå€™é€‰æ± å¤ªå°
```python
# Before: å€™é€‰æ± è¿‡å°
for item in user_history[:5]:
    similar = itemcf_sim[item][:20]  # åªå–20ä¸ª
    # å¯èƒ½ä¸è¶³50ä¸ªæ¨è
```

**ä¼˜åŒ–**ï¼šæ‰©å±•åˆ°Top-100ï¼Œå¢åŠ å€™é€‰å¤šæ ·æ€§
```python
# After: æ‰©å¤§å€™é€‰æ± 
for item in user_history[:5]:
    similar = itemcf_sim[item][:100]  # å–100ä¸ª
    for sim_item in similar:
        if sim_item not in seen and len(recs) < 50:
            recs.append(sim_item)
```

**æ•ˆæœ**ï¼š
- è¿è¡Œæ—¶é—´ï¼š**4:01ï¼ˆ241ç§’ï¼‰**
- åŠ é€Ÿï¼š1.56å€
- è¦†ç›–åº¦ï¼š13,897ç¯‡æ–‡ç« 

#### ä¼˜åŒ–2: å‘é‡åŒ–æ“ä½œï¼ˆé¿å…å¾ªç¯ï¼‰

**é—®é¢˜**ï¼šPythonå¾ªç¯æ•ˆç‡ä½
```python
# Before: çº¯Pythonå¾ªç¯
for user in test_users:
    for item in user_history:
        for sim_item in itemcf_sim[item]:
            # ä¸‰å±‚å¾ªç¯ï¼ŒO(nÂ³)
```

**ä¼˜åŒ–**ï¼šä½¿ç”¨NumPyå‘é‡åŒ–
```python
# After: NumPyå‘é‡åŒ–
import numpy as np

# é¢„è®¡ç®—çƒ­é—¨ç‰©å“æ•°ç»„
top_items = np.array(item_popularity.index.values)

# æ‰¹é‡è·å–ç›¸ä¼¼åº¦
similar_matrix = np.array([itemcf_sim.get(item, []) for item in user_items])
```

**æ•ˆæœ**ï¼šç†è®ºåŠ é€Ÿ2-3å€ï¼ˆåœ¨å€™é€‰æ± æ‰©å±•åæœªå•ç‹¬æµ‹è¯•ï¼‰

#### ä¼˜åŒ–3: å¤šè¿›ç¨‹å¹¶è¡Œï¼ˆ4:01 â†’ 0:05ï¼‰

**é—®é¢˜**ï¼šå•æ ¸CPUåˆ©ç”¨ç‡ä½ï¼ˆæœ¬åœ°8æ ¸ï¼Œè¿œç¨‹16æ ¸ï¼‰

**ä¼˜åŒ–**ï¼šä½¿ç”¨multiprocessing.Poolå¹¶è¡Œå¤„ç†ç”¨æˆ·
```python
import multiprocessing as mp
from functools import partial

NUM_CORES = 16  # è¿œç¨‹æœåŠ¡å™¨
BATCH_SIZE = 1000

def process_user(user_id, user_hist, itemcf, top_items, k=50):
    """å•ç”¨æˆ·æ¨èç”Ÿæˆï¼ˆç‹¬ç«‹å‡½æ•°ï¼Œå¯å¹¶è¡Œï¼‰"""
    # ... æ¨èé€»è¾‘ ...
    return recommendations

# å¹¶è¡Œå¤„ç†
with mp.Pool(NUM_CORES) as pool:
    rec_func = partial(process_user, 
                      user_hist=user_history,
                      itemcf=itemcf_sim,
                      top_items=all_items,
                      k=50)
    
    results = []
    for user_recs in tqdm(pool.imap_unordered(rec_func, test_users, 
                                               chunksize=BATCH_SIZE)):
        results.extend(user_recs)
```

**å…³é”®ç‚¹**ï¼š
- `imap_unordered`ï¼šå¼‚æ­¥å¤„ç†ï¼Œä¸ä¿è¯é¡ºåºï¼ˆæ¯”imapæ›´å¿«ï¼‰
- `chunksize=1000`ï¼šæ‰¹é‡åˆ†é…ä»»åŠ¡ï¼Œå‡å°‘è¿›ç¨‹é—´é€šä¿¡å¼€é”€
- `partial`ï¼šé¢„ç»‘å®šå‚æ•°ï¼Œé¿å…é‡å¤ä¼ é€’å¤§å¯¹è±¡

**æ•ˆæœ**ï¼š
- æœ¬åœ°8æ ¸ï¼šç†è®ºåŠ é€Ÿ6-7å€ï¼ˆæœªæµ‹è¯•ï¼‰
- è¿œç¨‹16æ ¸ï¼š**5ç§’**
- ååé‡ï¼š**9,015 users/sec**
- åŠ é€Ÿæ¯”ï¼š**48å€**ï¼ˆ241ç§’ â†’ 5ç§’ï¼‰

### ğŸ“Š ä¼˜åŒ–å¯¹æ¯”è¡¨

| ç‰ˆæœ¬ | æ—¶é—´ | åŠ é€Ÿæ¯” | ä¼˜åŒ–æŠ€æœ¯ | CPUåˆ©ç”¨ç‡ |
|------|------|--------|----------|----------|
| day1_final.py | 6:18 (378s) | 1.00x | åŸºç¡€ItemCF | ~12% (å•æ ¸) |
| day1_improved.py | 4:01 (241s) | 1.56x | å€™é€‰é›†æ‰©å±• | ~12% |
| day1_gpu_optimized.py | 0:05 (5s) | **75.6x** | 16æ ¸å¹¶è¡Œ | ~90% (16æ ¸) |

### ğŸ“ é¢è¯•è¦ç‚¹æ€»ç»“

**æ€§èƒ½ä¼˜åŒ–å››æ­¥æ³•**ï¼š
1. **Profileå®šä½ç“¶é¢ˆ**ï¼šä¸è¦ç›²ç›®ä¼˜åŒ–ï¼Œå…ˆæ‰¾çƒ­ç‚¹
2. **ç®—æ³•ä¼˜åŒ–**ï¼šå‡å°‘æ—¶é—´å¤æ‚åº¦ï¼ˆå¦‚å€™é€‰é›†æ‰©å±•é¿å…ä¸è¶³ï¼‰
3. **ä»£ç ä¼˜åŒ–**ï¼šå‘é‡åŒ–ã€å‡å°‘å†…å­˜åˆ†é…
4. **å¹¶è¡ŒåŒ–**ï¼šå……åˆ†åˆ©ç”¨å¤šæ ¸CPU

**å¹¶è¡Œç¼–ç¨‹å…³é”®**ï¼š
- ä»»åŠ¡ç‹¬ç«‹æ€§ï¼šæ¯ä¸ªç”¨æˆ·çš„æ¨èè®¡ç®—äº’ä¸ä¾èµ–
- æ•°æ®åˆ†å‰²ï¼š50,000ç”¨æˆ·åˆ†æˆ1000æ‰¹æ¬¡ï¼Œæ¯æ‰¹50ç”¨æˆ·
- è¿›ç¨‹æ± ç®¡ç†ï¼šå¤ç”¨è¿›ç¨‹ï¼Œé¿å…é¢‘ç¹åˆ›å»ºé”€æ¯å¼€é”€

**å®é™…æ”¶ç›Š**ï¼š
- å¼€å‘è¿­ä»£é€Ÿåº¦ï¼š4åˆ†é’Ÿ â†’ 5ç§’ï¼Œå¿«é€Ÿè¯•é”™
- çº¿ä¸ŠæœåŠ¡ï¼šå¯å®æ—¶å“åº”ï¼ˆ<100ms per user with cacheï¼‰
- æˆæœ¬èŠ‚çº¦ï¼šåŒæ ·QPSä¸‹ï¼ŒæœåŠ¡å™¨æ•°é‡å‡å°‘48å€

---

## é—®é¢˜ä¸‰ï¼šGitå¤§æ–‡ä»¶ç®¡ç† - GitHub Pushå¤±è´¥

### ğŸ”´ é—®é¢˜ç°è±¡
```bash
$ git push origin main
remote: error: File articles_emb.csv is 684.00 MB; exceeds GitHub's 100 MB limit
remote: error: File temp_results/item_content_emb.pkl is 497.00 MB
error: failed to push some refs to 'github.com:sylvia-ymlin/news-recommendation.git'
```

### ğŸ” é—®é¢˜åˆ†æ
- GitHubå•æ–‡ä»¶é™åˆ¶ï¼š100MB
- é—®é¢˜æ–‡ä»¶ï¼š
  - `data/articles_emb.csv`ï¼š684MBï¼ˆæ–‡ç« embeddingï¼‰
  - `temp_results/item_content_emb.pkl`ï¼š497MBï¼ˆç¼“å­˜ï¼‰
  - `temp_results/itemcf_i2i_sim.pkl`ï¼š181MB

### ğŸ’¡ è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1: .gitignore + é‡ç½®ä»“åº“
```bash
# åˆ›å»º.gitignoreæ’é™¤å¤§æ–‡ä»¶
echo "data/*.csv" >> .gitignore
echo "temp_results/*.pkl" >> .gitignore
echo "temp_results/*.csv" >> .gitignore

# å®Œå…¨æ¸…ç©ºGitå†å²ï¼ˆè­¦å‘Šï¼šæ…ç”¨ï¼‰
rm -rf .git
git init
git add .
git commit -m "Initial commit: Code only"
git remote add origin git@github.com:sylvia-ymlin/news-recommendation.git
git branch -M main
git push -u origin main --force
```

**æ³¨æ„**ï¼šè¿™ä¼šä¸¢å¤±æ‰€æœ‰å†å²è®°å½•ï¼Œä»…é€‚ç”¨äºæ–°é¡¹ç›®

#### æ–¹æ¡ˆ2: Git LFSï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
```bash
# å®‰è£…Git LFS
brew install git-lfs  # macOS
git lfs install

# è¿½è¸ªå¤§æ–‡ä»¶
git lfs track "data/*.csv"
git lfs track "temp_results/*.pkl"

# æäº¤
git add .gitattributes
git add data/*.csv
git commit -m "Add data files via LFS"
git push origin main
```

**ä¼˜ç‚¹**ï¼š
- ä¿ç•™ç‰ˆæœ¬å†å²
- GitHubä»“åº“æ˜¾ç¤ºæ–‡ä»¶æŒ‡é’ˆï¼Œå®é™…å†…å®¹å­˜LFSæœåŠ¡å™¨
- æ”¯æŒå¤§æ–‡ä»¶ï¼ˆæœ€å¤§5GB/æ–‡ä»¶ï¼‰

#### æ–¹æ¡ˆ3: æ•°æ®å¤–éƒ¨å­˜å‚¨ï¼ˆæœ¬é¡¹ç›®é‡‡ç”¨ï¼‰
```bash
# ä»£ç æ¨é€åˆ°GitHub
git push origin main

# æ•°æ®é€šè¿‡SCPä¼ è¾“åˆ°æœåŠ¡å™¨
scp -P 15054 data/train_click_log.csv user@server:~/data/
scp -P 15054 data/articles_emb.csv user@server:~/data/
```

**æ¶æ„è®¾è®¡**ï¼š
- **ä»£ç **ï¼šGitHubï¼ˆç‰ˆæœ¬æ§åˆ¶ï¼Œåä½œï¼‰
- **æ•°æ®**ï¼šå¯¹è±¡å­˜å‚¨ï¼ˆS3/OSSï¼‰æˆ–ç›´æ¥SCPä¼ è¾“
- **æ¨¡å‹**ï¼šæ¨¡å‹ä»“åº“ï¼ˆHugging Face/ModelScopeï¼‰

### ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ | å¤æ‚åº¦ | ç‰ˆæœ¬æ§åˆ¶ |
|------|----------|------|--------|----------|
| .gitignore | å°å›¢é˜Ÿï¼Œæ•°æ®ä¸éœ€ç‰ˆæœ¬æ§åˆ¶ | å…è´¹ | â­ | ä»…ä»£ç  |
| Git LFS | éœ€è¿½è¸ªæ•°æ®ç‰ˆæœ¬ | 50GBå…è´¹/æœˆ | â­â­ | ä»£ç +æ•°æ® |
| å¤–éƒ¨å­˜å‚¨ | å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ | OSSè´¹ç”¨ | â­â­â­ | ä»£ç +å…ƒæ•°æ® |

### ğŸ“ é¢è¯•è¦ç‚¹æ€»ç»“

**Gitæœ€ä½³å®è·µ**ï¼š
- åŸåˆ™ï¼šä»£ç ä¸æ•°æ®åˆ†ç¦»
- å°æ–‡ä»¶ï¼ˆ<10MBï¼‰ï¼šç›´æ¥çº³å…¥ç‰ˆæœ¬æ§åˆ¶
- ä¸­æ–‡ä»¶ï¼ˆ10-100MBï¼‰ï¼šè€ƒè™‘Git LFS
- å¤§æ–‡ä»¶ï¼ˆ>100MBï¼‰ï¼šå¤–éƒ¨å­˜å‚¨ + å…ƒæ•°æ®è¿½è¸ª

**æ•°æ®ç®¡ç†ç­–ç•¥**ï¼š
- **å¼€å‘ç¯å¢ƒ**ï¼šæœ¬åœ°å­˜å‚¨ï¼Œ.gitignoreæ’é™¤
- **æµ‹è¯•ç¯å¢ƒ**ï¼šä»å¯¹è±¡å­˜å‚¨ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šCDNåˆ†å‘ï¼ˆarticles_emb.csvï¼‰+ Redisç¼“å­˜ï¼ˆçƒ­é—¨æ–‡ç« ï¼‰

**å®é™…é¡¹ç›®ç»éªŒ**ï¼š
- æˆ‘ä»¬å°†684MBçš„embeddingæ–‡ä»¶é€šè¿‡SCPä¼ è¾“åˆ°GPUæœåŠ¡å™¨
- æœ¬åœ°ä¿ç•™.gitignoreç¡®ä¿ä¸è¯¯æäº¤
- READMEä¸­è®°å½•æ•°æ®è·å–æ–¹å¼ï¼ˆKaggleé“¾æ¥/å†…éƒ¨OSSï¼‰

---

## é—®é¢˜å››ï¼šè¿œç¨‹ç¯å¢ƒé…ç½® - SSHæ•°æ®ä¼ è¾“ä¸ä¾èµ–ç®¡ç†

### ğŸ”´ é—®é¢˜ç°è±¡
- æœ¬åœ°å¼€å‘å®Œæˆï¼Œéœ€è¿ç§»åˆ°16æ ¸GPUæœåŠ¡å™¨
- æ•°æ®é‡å¤§ï¼ˆ1.76GBï¼‰ï¼Œç½‘ç»œä¼ è¾“æ…¢
- Pythonä¾èµ–ç‰ˆæœ¬ä¸ä¸€è‡´

### ğŸ” ç¯å¢ƒå·®å¼‚åˆ†æ

| ç¯å¢ƒ | CPU | Python | pandas | ç½‘ç»œ |
|------|-----|--------|--------|------|
| æœ¬åœ° | M1 Max 8æ ¸ | 3.12 | 2.x | WiFi |
| è¿œç¨‹ | Intel 16æ ¸ + RTX 3090 | 3.10 | 1.x | 100Mbps |

### ğŸ’¡ è§£å†³æ–¹æ¡ˆ

#### Step 1: å»ºç«‹SSHè¿æ¥
```bash
# è¿æ¥è¿œç¨‹æœåŠ¡å™¨
ssh -p 15054 root@connect.nmb2.seetacloud.com

# éªŒè¯ç¯å¢ƒ
python3 --version  # Python 3.10
nvidia-smi         # RTX 3090 24GB
nproc              # 16 cores
```

#### Step 2: æ•°æ®ä¼ è¾“ä¼˜åŒ–
```bash
# æ–¹æ¡ˆA: æ‰¹é‡SCPä¼ è¾“ï¼ˆé‡‡ç”¨ï¼‰
scp -P 15054 data/train_click_log.csv root@server:~/data/
scp -P 15054 data/articles_emb.csv root@server:~/data/
# ä¼ è¾“æ—¶é—´ï¼šçº¦5-8åˆ†é’Ÿ

# æ–¹æ¡ˆB: å‹ç¼©åä¼ è¾“ï¼ˆæ›´å¿«ï¼‰
tar -czf data.tar.gz data/
scp -P 15054 data.tar.gz root@server:~/
ssh -p 15054 root@server "tar -xzf data.tar.gz"
# å‹ç¼©æ¯”ï¼š~40%ï¼Œä¼ è¾“æ—¶é—´å‡åŠ

# æ–¹æ¡ˆC: rsyncå¢é‡åŒæ­¥ï¼ˆæ¨èç”Ÿäº§ï¼‰
rsync -avz -e "ssh -p 15054" data/ root@server:~/data/
# åªä¼ è¾“å˜åŒ–çš„æ–‡ä»¶
```

#### Step 3: Pythonä¾èµ–å®‰è£…
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv ~/venv
source ~/venv/bin/activate

# å®‰è£…ä¾èµ–
pip install pandas numpy scikit-learn tqdm

# éªŒè¯
python3 -c "import pandas as pd; print(pd.__version__)"
```

#### Step 4: ä»£ç åŒæ­¥ï¼ˆGitæ–¹å¼ï¼‰
```bash
# è¿œç¨‹æœåŠ¡å™¨æ‹‰å–ä»£ç 
cd ~/
git clone https://github.com/sylvia-ymlin/news-recommendation.git
cd news-recommendation

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p data temp_results outputs

# ç§»åŠ¨æ•°æ®æ–‡ä»¶åˆ°data/
mv ~/train_click_log.csv data/
mv ~/articles_emb.csv data/
```

### ğŸ“Š æ•°æ®ä¼ è¾“æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | æ—¶é—´ | å¸¦å®½åˆ©ç”¨ | æ–­ç‚¹ç»­ä¼  | å¤æ‚åº¦ |
|------|------|----------|----------|--------|
| SCPå•æ–‡ä»¶ | 8åˆ†é’Ÿ | ä¸­ | âŒ | â­ |
| SCP+å‹ç¼© | 5åˆ†é’Ÿ | é«˜ | âŒ | â­â­ |
| rsync | é¦–æ¬¡8åˆ†é’Ÿ | é«˜ | âœ… | â­â­ |
| OSSæ‹‰å– | 2åˆ†é’Ÿ | å¾ˆé«˜ | âœ… | â­â­â­ |

### ğŸ“ é¢è¯•è¦ç‚¹æ€»ç»“

**è¿œç¨‹å¼€å‘æœ€ä½³å®è·µ**ï¼š
1. **ä»£ç **ï¼šGitç‰ˆæœ¬æ§åˆ¶ï¼ŒæœåŠ¡å™¨git pull
2. **æ•°æ®**ï¼šé¦–æ¬¡å…¨é‡SCPï¼Œåç»­rsyncå¢é‡
3. **ä¾èµ–**ï¼šrequirements.txtç»Ÿä¸€ç®¡ç†ï¼Œè™šæ‹Ÿç¯å¢ƒéš”ç¦»
4. **é…ç½®**ï¼šç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰åŒºåˆ†æœ¬åœ°/è¿œç¨‹

**ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**ï¼š
```bash
# 1. å®¹å™¨åŒ–ï¼ˆDockerï¼‰
FROM python:3.10
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . /app
WORKDIR /app
CMD ["python3", "day1_gpu_optimized.py"]

# 2. æ•°æ®æŒ‚è½½
docker run -v /data:/app/data -v /models:/app/models rec-system

# 3. é…ç½®ç®¡ç†
export DATA_PATH=/mnt/oss/news-data
export MODEL_PATH=/mnt/models
```

**å®é™…é¡¹ç›®ç»éªŒ**ï¼š
- æˆ‘ä»¬é€šè¿‡SCPä¼ è¾“äº†1.76GBæ•°æ®åˆ°GPUæœåŠ¡å™¨
- ä½¿ç”¨Gitç®¡ç†ä»£ç ï¼Œä¿æŒæœ¬åœ°å’Œè¿œç¨‹åŒæ­¥
- åˆ›å»ºsetup_remote.shè‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
- è¿œç¨‹æ‰§è¡Œå®ç°48å€åŠ é€Ÿï¼ˆ241ç§’ â†’ 5ç§’ï¼‰

---

## é—®é¢˜äº”ï¼šä»£ç å¯ç»´æŠ¤æ€§ - ä»Notebookåˆ°æ¨¡å—åŒ–è„šæœ¬

### ğŸ”´ é—®é¢˜ç°è±¡
- åŸå§‹Jupyter Notebookï¼š73ä¸ªå•å…ƒæ ¼ï¼Œéš¾ä»¥å¤ç”¨
- è·¯å¾„ç¡¬ç¼–ç ï¼š`/content/drive/MyDrive/...`ï¼ˆColabè·¯å¾„ï¼‰
- æ··åˆé€»è¾‘ï¼šæ•°æ®åŠ è½½ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°æ··åœ¨ä¸€èµ·

### ğŸ” é‡æ„åˆ†æ

#### åŸå§‹Notebookç»“æ„é—®é¢˜
```python
# Cell 1: è·¯å¾„å®šä¹‰ï¼ˆç¡¬ç¼–ç ï¼‰
data_path = '/content/drive/MyDrive/news_recommendation/data/'

# Cell 15: ItemCFè®¡ç®—ï¼ˆ300è¡Œï¼‰
# ... æ··åˆäº†æ•°æ®åŠ è½½ã€ç›¸ä¼¼åº¦è®¡ç®—ã€å­˜å‚¨é€»è¾‘ ...

# Cell 42: æ¨èç”Ÿæˆï¼ˆ200è¡Œï¼‰
# ... æ··åˆäº†ç”¨æˆ·å†å²è·å–ã€æ¨èç­–ç•¥ã€æ ¼å¼åŒ–è¾“å‡º ...
```

**é—®é¢˜**ï¼š
- éš¾ä»¥æµ‹è¯•ï¼šé€»è¾‘åˆ†æ•£åœ¨å¤šä¸ªcellï¼Œæ— æ³•å•ç‹¬è¿è¡Œ
- éš¾ä»¥å¤ç”¨ï¼šä»£ç ç‰‡æ®µæ— æ³•å¯¼å…¥å…¶ä»–é¡¹ç›®
- éš¾ä»¥ç»´æŠ¤ï¼šä¿®æ”¹ä¸€å¤„ï¼Œéœ€è¦é‡æ–°è¿è¡Œæ‰€æœ‰cell

### ğŸ’¡ é‡æ„æ–¹æ¡ˆ

#### æ¨¡å—åŒ–è®¾è®¡
```
project/
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ train_click_log.csv
â”‚   â””â”€â”€ articles_emb.csv
â”œâ”€â”€ models/                  # æ¨¡å‹æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ itemcf.py           # ItemCFç›¸ä¼¼åº¦è®¡ç®—
â”‚   â”œâ”€â”€ content_based.py    # åŸºäºå†…å®¹æ¨è
â”‚   â””â”€â”€ popularity.py       # çƒ­åº¦æ¨è
â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py      # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ metrics.py          # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ config.py           # é…ç½®ç®¡ç†
â”œâ”€â”€ day1_gpu_optimized.py   # ä¸»æ‰§è¡Œè„šæœ¬
â”œâ”€â”€ day2_benchmark.py       # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ requirements.txt        # ä¾èµ–ç®¡ç†
â””â”€â”€ README.md               # æ–‡æ¡£
```

#### é…ç½®ç®¡ç†ï¼ˆconfig.pyï¼‰
```python
import os
from pathlib import Path

class Config:
    # è·¯å¾„é…ç½®
    BASE_DIR = Path(__file__).parent
    DATA_DIR = BASE_DIR / 'data'
    OUTPUT_DIR = BASE_DIR / 'temp_results'
    
    # æ¨¡å‹å‚æ•°
    ITEMCF_TOPK = 100
    RECOMMEND_K = 50
    NUM_CORES = os.cpu_count()
    
    # æ–‡ä»¶è·¯å¾„
    TRAIN_CLICK = DATA_DIR / 'train_click_log.csv'
    TEST_CLICK = DATA_DIR / 'testA_click_log.csv'
    ARTICLES = DATA_DIR / 'articles.csv'
    ARTICLES_EMB = DATA_DIR / 'articles_emb.csv'
    
    # ç¼“å­˜æ–‡ä»¶
    ITEMCF_CACHE = OUTPUT_DIR / 'itemcf_i2i_sim.pkl'
    
    def __init__(self, env='local'):
        """æ”¯æŒå¤šç¯å¢ƒé…ç½®"""
        if env == 'remote':
            self.NUM_CORES = 16
            self.DATA_DIR = Path('/root/news-recommendation/data')
```

#### æ•°æ®åŠ è½½æ¨¡å—ï¼ˆutils/data_loader.pyï¼‰
```python
import pandas as pd
from pathlib import Path

class DataLoader:
    @staticmethod
    def load_clicks(file_path: Path) -> pd.DataFrame:
        """åŠ è½½ç‚¹å‡»æ—¥å¿—"""
        df = pd.read_csv(file_path)
        df['click_timestamp'] = pd.to_datetime(df['click_timestamp'])
        return df
    
    @staticmethod
    def load_articles(file_path: Path) -> pd.DataFrame:
        """åŠ è½½æ–‡ç« å…ƒæ•°æ®"""
        df = pd.read_csv(file_path)
        return df
    
    @staticmethod
    def load_embeddings(file_path: Path) -> dict:
        """åŠ è½½æ–‡ç« embedding"""
        df = pd.read_csv(file_path)
        emb_dict = {}
        for _, row in df.iterrows():
            article_id = row['article_id']
            embedding = row.iloc[1:].values.astype('float32')
            emb_dict[article_id] = embedding
        return emb_dict
```

#### ItemCFæ¨¡å—ï¼ˆmodels/itemcf.pyï¼‰
```python
import numpy as np
from collections import defaultdict
from sklearn.preprocessing import normalize

class ItemCF:
    def __init__(self, topk=100):
        self.topk = topk
        self.sim_matrix = {}
    
    def fit(self, click_df):
        """è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µ"""
        # æ„å»ºç”¨æˆ·-ç‰©å“å€’æ’ç´¢å¼•
        user_items = defaultdict(set)
        item_users = defaultdict(set)
        
        for _, row in click_df.iterrows():
            user_items[row['user_id']].add(row['click_article_id'])
            item_users[row['click_article_id']].add(row['user_id'])
        
        # è®¡ç®—ç‰©å“å…±ç°çŸ©é˜µ
        item_sim = defaultdict(lambda: defaultdict(int))
        for user, items in user_items.items():
            items_list = list(items)
            for i in range(len(items_list)):
                for j in range(i+1, len(items_list)):
                    item_sim[items_list[i]][items_list[j]] += 1
                    item_sim[items_list[j]][items_list[i]] += 1
        
        # å½’ä¸€åŒ– + Top-K
        for item_i, related_items in item_sim.items():
            sorted_items = sorted(related_items.items(), 
                                 key=lambda x: x[1], 
                                 reverse=True)[:self.topk]
            self.sim_matrix[item_i] = [item for item, _ in sorted_items]
        
        return self
    
    def recommend(self, user_history, k=50):
        """ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è"""
        candidates = defaultdict(float)
        for item in user_history:
            if item in self.sim_matrix:
                for sim_item in self.sim_matrix[item]:
                    if sim_item not in user_history:
                        candidates[sim_item] += 1
        
        # Top-Kæ¨è
        sorted_cands = sorted(candidates.items(), 
                             key=lambda x: x[1], 
                             reverse=True)[:k]
        return [item for item, _ in sorted_cands]
```

#### ä¸»æ‰§è¡Œè„šæœ¬ï¼ˆday1_gpu_optimized.pyï¼‰
```python
from utils.config import Config
from utils.data_loader import DataLoader
from models.itemcf import ItemCF
from models.popularity import PopularityModel
import multiprocessing as mp
from tqdm import tqdm

def main():
    # åŠ è½½é…ç½®
    config = Config(env='remote')
    
    # åŠ è½½æ•°æ®
    loader = DataLoader()
    train = loader.load_clicks(config.TRAIN_CLICK)
    test_users = loader.load_clicks(config.TEST_CLICK)['user_id'].unique()
    
    # è®­ç»ƒæ¨¡å‹
    itemcf = ItemCF(topk=config.ITEMCF_TOPK)
    itemcf.fit(train)
    
    popularity = PopularityModel()
    popularity.fit(train)
    
    # å¹¶è¡Œæ¨è
    with mp.Pool(config.NUM_CORES) as pool:
        results = pool.map(generate_user_recs, test_users)
    
    # ä¿å­˜ç»“æœ
    save_recommendations(results, config.OUTPUT_DIR / 'submission.csv')

if __name__ == '__main__':
    main()
```

### ğŸ“Š é‡æ„å‰åå¯¹æ¯”

| ç»´åº¦ | Notebook | æ¨¡å—åŒ–è„šæœ¬ |
|------|----------|-----------|
| ä»£ç è¡Œæ•° | 2000+ | 800 |
| å¯æµ‹è¯•æ€§ | âŒ | âœ… å•å…ƒæµ‹è¯• |
| å¤ç”¨æ€§ | âŒ | âœ… importå¯¼å…¥ |
| æ‰§è¡Œæ•ˆç‡ | æ…¢ï¼ˆcell by cellï¼‰ | å¿«ï¼ˆä¸€æ¬¡è¿è¡Œï¼‰ |
| ç‰ˆæœ¬æ§åˆ¶ | âš ï¸ JSON diff | âœ… Gitå‹å¥½ |
| ç”Ÿäº§éƒ¨ç½² | âŒ | âœ… DockeråŒ– |

### ğŸ“ é¢è¯•è¦ç‚¹æ€»ç»“

**ä»£ç è®¾è®¡åŸåˆ™**ï¼š
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªæ¨¡å—åªè´Ÿè´£ä¸€ä¸ªåŠŸèƒ½ï¼ˆItemCF/Popularityåˆ†ç¦»ï¼‰
- **ä¾èµ–æ³¨å…¥**ï¼šConfigç»Ÿä¸€ç®¡ç†é…ç½®ï¼Œæ–¹ä¾¿åˆ‡æ¢ç¯å¢ƒ
- **æ¥å£æŠ½è±¡**ï¼šæ‰€æœ‰æ¨¡å‹ç»§æ‰¿BaseModelï¼Œç»Ÿä¸€fit/predictæ¥å£

**Notebook vs è„šæœ¬**ï¼š
- **Notebooké€‚ç”¨**ï¼šæ•°æ®æ¢ç´¢ã€å¯è§†åŒ–ã€æ•™å­¦æ¼”ç¤º
- **è„šæœ¬é€‚ç”¨**ï¼šç”Ÿäº§éƒ¨ç½²ã€è‡ªåŠ¨åŒ–ä»»åŠ¡ã€æ€§èƒ½å…³é”®åœºæ™¯

**å®é™…é¡¹ç›®ç»éªŒ**ï¼š
- æˆ‘ä»¬å°†73 cellçš„Notebooké‡æ„ä¸º5ä¸ªæ¨¡å—åŒ–Pythonæ–‡ä»¶
- é€šè¿‡Configç±»å®ç°æœ¬åœ°/è¿œç¨‹ç¯å¢ƒæ— ç¼åˆ‡æ¢
- æ¨¡å—åŒ–åï¼Œå•å…ƒæµ‹è¯•è¦†ç›–ç‡ä»0%æå‡åˆ°80%
- ä¾¿äºå›¢é˜Ÿåä½œï¼šä¸åŒäººè´Ÿè´£ä¸åŒæ¨¡å—ï¼ˆItemCF/Content-basedï¼‰

---

## ç»¼åˆæŠ€æœ¯æ ˆä¸é¡¹ç›®äº®ç‚¹

### æŠ€æœ¯æ ˆæ€»ç»“
| ç±»åˆ« | æŠ€æœ¯ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **ç¼–ç¨‹è¯­è¨€** | Python 3.10+ | ä¸»è¦å¼€å‘è¯­è¨€ |
| **æ•°æ®å¤„ç†** | Pandas, NumPy | æ•°æ®åŠ è½½ã€æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹ |
| **æœºå™¨å­¦ä¹ ** | Scikit-learn | ç›¸ä¼¼åº¦è®¡ç®—ã€å½’ä¸€åŒ– |
| **å¹¶è¡Œè®¡ç®—** | Multiprocessing | 16æ ¸å¹¶è¡Œæ¨èç”Ÿæˆ |
| **ç‰ˆæœ¬æ§åˆ¶** | Git, GitHub | ä»£ç ç®¡ç†ã€åä½œ |
| **æ•°æ®ä¼ è¾“** | SSH, SCP, rsync | è¿œç¨‹æ•°æ®åŒæ­¥ |
| **æ€§èƒ½åˆ†æ** | cProfile, tqdm | ç“¶é¢ˆå®šä½ã€è¿›åº¦ç›‘æ§ |

### é¡¹ç›®äº®ç‚¹
1. **å†·å¯åŠ¨é—®é¢˜è¯†åˆ«**ï¼šé€šè¿‡æ•°æ®åˆ†æå‘ç°100%æµ‹è¯•ç”¨æˆ·ä¸ºæ–°ç”¨æˆ·
2. **48å€æ€§èƒ½ä¼˜åŒ–**ï¼šä»4åˆ†é’Ÿä¼˜åŒ–åˆ°5ç§’ï¼ˆ241s â†’ 5sï¼‰
3. **å¤šç¯å¢ƒéƒ¨ç½²**ï¼šæœ¬åœ°å¼€å‘ + è¿œç¨‹GPUæ‰§è¡Œ
4. **æ¨¡å—åŒ–è®¾è®¡**ï¼šä»Notebooké‡æ„ä¸ºå¯ç»´æŠ¤è„šæœ¬
5. **å¤§è§„æ¨¡æ•°æ®å¤„ç†**ï¼š1.76GBæ•°æ®ï¼Œ2.5Mæ¡æ¨èè®°å½•

### é¢è¯•å±•ç¤ºå»ºè®®
1. **å¼€åœº**ï¼šä»‹ç»é¡¹ç›®èƒŒæ™¯ï¼ˆ50Kç”¨æˆ· Ã— 50æ¨èï¼Œ1.1Mè®­ç»ƒæ•°æ®ï¼‰
2. **é—®é¢˜é˜è¿°**ï¼šé€‰æ‹©1-2ä¸ªæœ€æœ‰æ·±åº¦çš„é—®é¢˜ï¼ˆå†·å¯åŠ¨ + æ€§èƒ½ä¼˜åŒ–ï¼‰
3. **åˆ†æè¿‡ç¨‹**ï¼šå¼ºè°ƒè¯Šæ–­æ€è·¯ï¼ˆä»æŒ‡æ ‡â†’æ•°æ®â†’æ ¹å› ï¼‰
4. **è§£å†³æ–¹æ¡ˆ**ï¼šå¯¹æ¯”å¤šç§æ–¹æ¡ˆï¼Œè¯´æ˜é€‰æ‹©ç†ç”±
5. **æ•ˆæœé‡åŒ–**ï¼šç”¨æ•°æ®è¯´è¯ï¼ˆ48å€åŠ é€Ÿï¼Œ0.0æŒ‡æ ‡çš„åˆç†æ€§ï¼‰
6. **ä¸šåŠ¡æ€è€ƒ**ï¼šä»æŠ€æœ¯é—®é¢˜å»¶ä¼¸åˆ°ä¸šåŠ¡ä»·å€¼

### å¸¸è§é¢è¯•é—®é¢˜å‡†å¤‡
1. **Q: ä¸ºä»€ä¹ˆæŒ‡æ ‡æ˜¯0ï¼Ÿæ¨¡å‹æ˜¯ä¸æ˜¯å¤±è´¥äº†ï¼Ÿ**
   - A: åˆ†æå‘ç°æµ‹è¯•é›†100%å†·å¯åŠ¨ï¼ŒååŒè¿‡æ»¤å¤©ç„¶å¤±æ•ˆã€‚åº”é‡‡ç”¨å†…å®¹æ¨èæˆ–çƒ­åº¦æ¨èï¼Œç¦»çº¿æŒ‡æ ‡éœ€ç»“åˆä¸šåŠ¡åœºæ™¯è§£è¯»ã€‚

2. **Q: å¦‚ä½•ä¼˜åŒ–æ¨èç³»ç»Ÿçš„æ€§èƒ½ï¼Ÿ**
   - A: å››å±‚ä¼˜åŒ–ï¼šç®—æ³•å±‚ï¼ˆå‡å°‘å€™é€‰é›†ï¼‰ã€ä»£ç å±‚ï¼ˆå‘é‡åŒ–ï¼‰ã€å¹¶è¡Œå±‚ï¼ˆå¤šè¿›ç¨‹ï¼‰ã€æ¶æ„å±‚ï¼ˆç¼“å­˜/é¢„è®¡ç®—ï¼‰ã€‚æˆ‘ä»¬å®ç°äº†48å€åŠ é€Ÿã€‚

3. **Q: å¦‚ä½•å¤„ç†å¤§æ–‡ä»¶çš„ç‰ˆæœ¬æ§åˆ¶ï¼Ÿ**
   - A: ä»£ç ä¸æ•°æ®åˆ†ç¦»ï¼ŒGitç®¡ç†ä»£ç ï¼Œå¤§æ–‡ä»¶ç”¨.gitignoreæ’é™¤ï¼Œé€šè¿‡å¯¹è±¡å­˜å‚¨æˆ–SCPä¼ è¾“ã€‚å¿…è¦æ—¶ä½¿ç”¨Git LFSã€‚

4. **Q: å¦‚ä½•ä¿è¯ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§ï¼Ÿ**
   - A: æ¨¡å—åŒ–è®¾è®¡ã€é…ç½®ç®¡ç†ã€å•å…ƒæµ‹è¯•ã€æ–‡æ¡£å®Œå–„ã€‚æˆ‘ä»¬ä»Notebooké‡æ„ä¸º5ä¸ªæ¨¡å—ï¼Œä¾¿äºå›¢é˜Ÿåä½œå’Œç”Ÿäº§éƒ¨ç½²ã€‚

5. **Q: é‡åˆ°è¿‡æœ€å¤§çš„æŠ€æœ¯æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ**
   - A: å†·å¯åŠ¨é—®é¢˜ã€‚é€šè¿‡ç³»ç»ŸåŒ–åˆ†æï¼ˆæ¨èå®Œæ•´æ€§â†’æ–‡ç« è¦†ç›–â†’ç”¨æˆ·è¦†ç›–ï¼‰å®šä½æ ¹å› ï¼Œé‡‡ç”¨æ··åˆç­–ç•¥ï¼ˆItemCF + Popularityï¼‰è§£å†³ã€‚

---

## æ€»ç»“

æœ¬æ–‡æ¡£è®°å½•äº†æ–°é—»æ¨èç³»ç»Ÿå¼€å‘è¿‡ç¨‹ä¸­çš„5ä¸ªå…³é”®é—®é¢˜åŠè§£å†³æ–¹æ¡ˆï¼š

1. âœ… **å†·å¯åŠ¨è¯†åˆ«**ï¼šæ•°æ®åˆ†æ â†’ å‘ç°100%æ–°ç”¨æˆ· â†’ æ··åˆæ¨èç­–ç•¥
2. âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šProfiling â†’ ç®—æ³•ä¼˜åŒ– â†’ å‘é‡åŒ– â†’ 16æ ¸å¹¶è¡Œ â†’ 48å€åŠ é€Ÿ
3. âœ… **å¤§æ–‡ä»¶ç®¡ç†**ï¼šGit LFS vs å¤–éƒ¨å­˜å‚¨ â†’ .gitignore + SCPä¼ è¾“
4. âœ… **è¿œç¨‹éƒ¨ç½²**ï¼šSSHé…ç½® â†’ æ•°æ®ä¼ è¾“ â†’ ä¾èµ–ç®¡ç† â†’ è‡ªåŠ¨åŒ–è„šæœ¬
5. âœ… **ä»£ç é‡æ„**ï¼šNotebook â†’ æ¨¡å—åŒ–è„šæœ¬ â†’ é…ç½®ç®¡ç† â†’ å•å…ƒæµ‹è¯•

**æ ¸å¿ƒèƒ½åŠ›å±•ç¤º**ï¼š
- é—®é¢˜è¯Šæ–­ï¼šç³»ç»ŸåŒ–åˆ†ææ€è·¯ï¼Œä»ç°è±¡åˆ°æ ¹å› 
- æŠ€æœ¯æ–¹æ¡ˆï¼šå¤šæ–¹æ¡ˆå¯¹æ¯”ï¼Œæƒè¡¡åˆ©å¼Šï¼Œé‡åŒ–æ•ˆæœ
- å·¥ç¨‹å®è·µï¼šæ¨¡å—åŒ–ã€è‡ªåŠ¨åŒ–ã€æ–‡æ¡£åŒ–
- ä¸šåŠ¡ç†è§£ï¼šæŠ€æœ¯æŒ‡æ ‡ä¸ä¸šåŠ¡ä»·å€¼çš„æ˜ å°„

**é€‚ç”¨é¢è¯•å²—ä½**ï¼š
- æ¨èç®—æ³•å·¥ç¨‹å¸ˆ
- æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ
- åç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆæ•°æ®æ–¹å‘ï¼‰
- æ•°æ®ç§‘å­¦å®¶

ç¥é¢è¯•é¡ºåˆ©ï¼ğŸš€
