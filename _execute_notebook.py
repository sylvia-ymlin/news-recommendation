# Cell 1
from pathlib import Path

base_path = Path.cwd()

data_path = str(base_path / 'data') + '/'

save_path = str(base_path / 'temp_results') + '/'

Path(data_path).mkdir(parents=True, exist_ok=True)

Path(save_path).mkdir(parents=True, exist_ok=True)

# Cell 5
import subprocess

import sys



subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'faiss-cpu', 'tqdm'])



import os, math, warnings, math, pickle, random

from pathlib import Path

from datetime import datetime

from collections import defaultdict

import logging

warnings.filterwarnings('ignore')

os.environ['OMP_NUM_THREADS'] = '1'

logger = logging.getLogger(__name__)

logger.setLevel(logging.INFO)



import faiss

import pandas as pd

import numpy as np

from tqdm import tqdm





from sklearn.preprocessing import MinMaxScaler

from sklearn.preprocessing import LabelEncoder

from sklearn.preprocessing import LabelEncoder

# Cell 6
from pathlib import Path

base_path = Path.cwd()

data_path = str(base_path / 'data') + '/'

save_path = str(base_path / 'temp_results') + '/'

Path(data_path).mkdir(parents=True, exist_ok=True)

Path(save_path).mkdir(parents=True, exist_ok=True)

# åšå¬å›è¯„ä¼°çš„ä¸€ä¸ªæ ‡å¿—, å¦‚æœä¸è¿›è¡Œè¯„ä¼°å°±æ˜¯ç›´æ¥ä½¿ç”¨å…¨é‡æ•°æ®è¿›è¡Œå¬å›

metric_recall = False

# Cell 8
# debug mode
def get_all_click_sample(data_path, sample_nums=10000):
    all_click = pd.read_csv(data_path + 'train_click_log.csv')
    all_user_ids = all_click.user_id.unique() # è·å¾—å»é‡çš„ user_id

    # randomly choose, don't put back
    random.seed(42)
    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False)
    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]

    # drop repeated records
    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))

    return all_click

# Cell 9
# online and off-line
def get_all_click_df(data_path, offline=True):
  if offline:
    all_click = pd.read_csv(data_path + 'train_click_log.csv')
  else:
    trn_click = pd.read_csv(data_path + 'train_click_log.csv')
    tst_click = pd.read_csv(data_path + 'testA_click_log.csv')

    all_click = pd.concat([trn_click, tst_click])

  # å»é‡
  all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))

  return all_click

# Cell 10
# load from article.csv
def get_item_info_df(data_path):
  item_info_df = pd.read_csv(data_path + 'articles.csv')

  # ä¸ºäº†æ–¹ä¾¿ä¸è®­ç»ƒé›†ä¸­çš„ click_article_id å¯¹åº”ï¼Œéœ€è¦æŠŠ article_id ä¿®æ”¹
  item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})

  return item_info_df

# Cell 11
# load embedding
def get_item_emb_dict(data_path, save_path):
  item_emb_df = pd.read_csv(data_path + 'articles_emb.csv')

  # é€šè¿‡åˆ—åé‡ŒåŒ…å« 'emb' æ¥å®šä½å‘é‡çš„æ¯ä¸€ç»´ï¼ˆå¦‚ emb_0, emb_1, ...ï¼‰
  item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]
  # è½¬æˆè¿ç»­å†…å­˜çš„ NumPy çŸ©é˜µ
  item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols])

  # L2 å½’ä¸€åŒ–
  # ç”¨æ¯è¡Œçš„èŒƒæ•°æŠŠè¯¥è¡Œé™¤ä¸€ä¸‹ï¼Œä½¿æ¯ä¸ªå‘é‡é•¿åº¦ä¸º 1ï¼Œåç»­ å†…ç§¯ å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦
  # è‹¥ç”¨ FAISS çš„ IndexFlatIP (å†…ç§¯ä½œç›¸ä¼¼åº¦)ï¼Œå¿…é¡»å…ˆåšè¿™ä¸€æ­¥
  item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)
  # ç»„è£…æˆå­—å…¸ï¼šç”Ÿæˆ {article_id â†’ å‘é‡} çš„æŸ¥æ‰¾è¡¨
  item_emb_dict = dict(zip(item_emb_df['article_id'], item_emb_np))
  # æŒä¹…åŒ–åˆ°æœ¬åœ°
  pickle.dump(item_emb_dict, open(save_path + 'item_content_emb.pkl', 'wb'))

  return item_emb_dict

# Cell 12
# æœ€å°-æœ€å¤§å½’ä¸€åŒ–
max_min_scaler = lambda x: (x - np.min(x))/(np.max(x) - np.min(x))

# Cell 13
all_click_df = get_all_click_df(data_path, offline=False)
# å¯¹æ—¶é—´æˆ³å½’ä¸€åŒ–
all_click_df['click_timestamp'] = all_click_df[['click_timestamp']].apply(max_min_scaler)

# Cell 14
item_info_df = get_item_info_df(data_path)
# å¯¹æ–‡ç« åˆ›å»ºæ—¶é—´å½’ä¸€åŒ–
item_info_df['created_at_ts'] = item_info_df[['created_at_ts']].apply(max_min_scaler)

# Cell 15
item_emb_dict = get_item_emb_dict(data_path, save_path)

# Cell 17
# è·å– ç”¨æˆ·-æ–‡ç« -æ—¶é—´
#  {user1: [(item1, time1), (item2, time2)..]...}
# ç”¨äºåŸºäºå…³è”è§„åˆ™çš„ ç”¨æˆ·ååŒè¿‡æ»¤
def get_user_item_time(click_df):
  click_df = click_df.sort_values('click_timestamp')

  def make_item_time_pair(df):
    return list(zip(df['click_article_id'], df['click_timestamp']))

  # group by user_id, takeout 'click_article_id', 'click_timestamp'
  user_item_time_df = click_df.groupby('user_id')[['click_article_id', 'click_timestamp']] \
      .apply(lambda x: make_item_time_pair(x)).reset_index().rename(columns={0: 'item_time_list'})

  # è½¬æ¢ä¸ºå­—å…¸
  user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))

  return user_item_time_dict

# Cell 18
# è·å– æ–‡ç« -ç”¨æˆ·-æ—¶é—´
# {item1: [(user1, time1), (user2, time2)...]...}
# ç”¨äºåŸºäºå…³è”è§„åˆ™çš„ ç‰©å“ååŒè¿‡æ»¤
def get_item_user_time(click_df):
  click_df = click_df.sort_values('click_timestamp')

  def make_user_time_pair(df):
    return list(zip(df['user_id'], df['click_timestamp']))

  item_user_time_df = click_df.groupby('click_article_id')[['user_id', 'click_timestamp']] \
    .apply(lambda x: make_user_time_pair(x)).reset_index().rename(columns={0: 'user_time_list'})

  item_user_time_dict = dict(zip(item_user_time_df['click_article_id'], item_user_time_df['user_time_list']))

  return item_user_time_dict

# Cell 19
# è·å–å½“å‰æ•°æ®çš„å†å²ç‚¹å‡»å’Œæœ€åä¸€æ¬¡ç‚¹å‡»
# ç”¨æˆ·è¯„ä¼°å¬å›ç»“æœ
# ç”¨äºç‰¹å¾å·¥ç¨‹
# ç”¨äºåˆ¶ä½œæ ‡ç­¾ï¼Œè½¬æˆç›‘ç£å­¦ä¹ æµ‹è¯•é›†
def get_hist_and_last_click(click_df):
  # æŒ‰ç”¨æˆ·æ’åºï¼ŒåŒä¸€ä¸ªç”¨æˆ·æŒ‰ç…§æ—¶é—´å‡åº
  all_click = click_df.sort_values(by=['user_id', 'click_timestamp'])
  # è·å–æ¯ä¸ªç”¨æˆ·çš„æœ€åä¸€æ¬¡ç‚¹å‡»
  click_last_df = all_click.groupby('user_id').tail(1)

  # ç”¨æˆ·æœ€åä¸€æ¬¡ç‚¹å‡»è¦ä»æ—¥å¿—ä¸­å‰”é™¤ï¼Œä½†æ˜¯å¦‚æœç”¨æˆ·æœ¬èº«åªæœ‰ä¸€æ¬¡ç‚¹å‡»ï¼Œä¸ºäº†é¿å…æ•°æ®ç¼ºå¤±ï¼Œåˆ™ä¸å‰”é™¤
  def hist_func(user_df):
    if len(user_df) == 1:
      return user_df
    else:
      return user_df[:-1]

  click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)

  return click_hist_df, click_last_df

  # è·å–æ¯ä¸ªç”¨æˆ·çš„å†å²ç‚¹å‡»
  # drop=True: æŠŠå½“å‰ç´¢å¼•ä¸¢å¼ƒï¼Œé‡æ–°ç”Ÿæˆä» 0 å¼€å§‹çš„è¿ç»­è¡Œå·ç´¢å¼•
  click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)

  return click_hist_df, click_last_df


# Cell 20
# è·å–æ–‡ç« å±æ€§
def get_item_info_dict(item_info_df):
  # å°†æ–‡ç« å’Œæ–‡ç« å„ä¸ªå±æ€§éƒ½åšä¸€ä¸ªå­—å…¸
  item_type_dict = dict(zip(item_info_df['click_article_id'], item_info_df['category_id']))
  item_words_dict = dict(zip(item_info_df['click_article_id'], item_info_df['words_count']))
  item_created_time_dict = dict(zip(item_info_df['click_article_id'], item_info_df['created_at_ts']))

  return item_type_dict, item_words_dict, item_created_time_dict

# Cell 21
# è·å–ç”¨æˆ·å†å²ç‚¹å‡»æ–‡ç« çš„ä¿¡æ¯
def get_user_hist_item_info_dict(all_click):
  # ç”¨æˆ·å†å²ç‚¹å‡»çš„æ–‡ç« çš„ç±»å‹
  user_hist_item_typs = all_click.groupby('user_id')['category_id'].agg(set).reset_index()
  # è½¬ä¸ºå­—å…¸
  user_hist_item_typs_dict = dict(zip(user_hist_item_typs['user_id'], user_hist_item_typs['category_id']))

  # æ–‡ç« çš„é›†åˆ
  user_hist_item_ids_dict = all_click.groupby('user_id')['click_article_id'].agg(set).reset_index()
  user_hist_item_ids_dict = dict(zip(user_hist_item_ids_dict['user_id'], user_hist_item_ids_dict['click_article_id']))

  # æ–‡ç« å¹³å‡å­—æ•°
  user_hist_item_words = all_click.groupby('user_id')['words_count'].agg('mean').reset_index()
  user_hist_item_words_dict = dict(zip(user_hist_item_words['user_id'], user_hist_item_words['words_count']))

  # æœ€åä¸€æ¬¡ç‚¹å‡»çš„æ–‡ç« çš„åˆ›å»ºæ—¶é—´
  all_click_ = all_click.sort_values('click_timestamp')
  user_last_item_created_time = all_click_.groupby('user_id')['created_at_ts'].apply(lambda x: x.iloc[-1]).reset_index()
  user_last_item_created_time_dict = dict(zip(user_last_item_created_time['user_id'], \
                                                user_last_item_created_time['created_at_ts']))

  return user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict


# Cell 22
# ç‚¹å‡»æ¬¡æ•°æœ€å¤šçš„topkä¸ªæ–‡ç« 
def get_item_topk_click(click_df, k):
  topk_click = click_df['click_article_id'].value_counts().index[:k]
  return topk_click

# Cell 24
# è¿™é‡Œå®ç°äº†äº”ä¸ªå¬å›é€šé“
user_multi_recall_dict =  {'itemcf_sim_itemcf_recall': {},
                           'embedding_sim_item_recall': {},
                           'youtubednn_recall': {},
                           'youtubednn_usercf_recall': {},
                           'cold_start_recall': {}}

# Cell 25
item_type_dict, item_words_dict, item_created_time_dict = get_item_info_dict(item_info_df)

# Cell 26
# æå–æ•°æ®ï¼Œoffline, æœ€åä¸€æ¬¡ç‚¹å‡»ç”¨ä½œå¬å›è¯„ä¼°
trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)

# Cell 28
# ä¾æ¬¡è¯„ä¼°å¬å›ä¸­å‰ 10ï¼Œ 20ï¼Œ 30ï¼Œ 40ï¼Œ 50 ä¸ªæ–‡ç« ä¸­çš„å‡»ä¸­ç‡
# è¶Šé å‰ï¼Œè¯´æ˜å¬å›çš„æ•ˆæœè¶Šå¥½ï¼Œä¸æ˜¯ä¸€å®šè¦æ§åˆ¶å¬å›çš„æ•°é‡ï¼Œä½†æ˜¯å¦‚æœå¤šç¯‡å¬å›éƒ½æ²¡æœ‰å‘½ä¸­ï¼Œå¬å›ç®—æ³•æ˜¯æœ‰é—®é¢˜çš„
def metrics_recall(user_recall_items_dict, trn_last_click_df, topk=5):
  # éœ€è¦ (user_id, click_article_id)
  last_click_item_dict = dict(zip(trn_last_click_df['user_id'], trn_last_click_df['click_article_id']))

  user_num = len(user_recall_items_dict)

  for k in range(10, topk+1, 10):
    hit_num = 0
    for user, item_list in user_recall_items_dict.items():
      # è·å–å‰ k å¬å›ç»“æœ
      tmp_recall_items = [x[0] for x in user_recall_items_dict[user][:k]]
      if last_click_item_dict[user] in set(tmp_recall_items):
        hit_num += 1

  # æœ‰å¤šå°‘ç”¨æˆ·å‘½ä¸­
  hit_rate = round(hit_num * 100.0 / user_num, 2)
  logger.info('topk: {}, hit_num: {}, hit_rate: {}'.format(k, hit_num, hit_rate))
  return hit_rate # æœ€åè¿”å›çš„æ˜¯ ä¼ å…¥å‚æ•° topk çš„å‘½ä¸­ç‡

# Cell 31
def itemcf_sim(df, item_created_time_dict):
  # item_created_time_dict: å…¶å®å°±æ˜¯ç´¢å¼•
  user_item_time_dict = get_user_item_time(df)

  # å­˜æ”¾ç‰©å“ç›¸ä¼¼åº¦
  i2i_sim = {}
  # ç»Ÿè®¡ç‰©å“è¢«ç‚¹å‡»æ¬¡æ•°
  item_cnt = defaultdict(int)
  for user, item_time_list in tqdm(user_item_time_dict.items()):
    # è€ƒè™‘æ—¶é—´å› ç´  [loc1 å…¶å®æ˜¯ index]
    for loc1, (item1, time1) in enumerate(item_time_list):
      item_cnt[item1] += 1
      i2i_sim.setdefault(item1, {})
      for loc2, (item2, time2) in enumerate(item_time_list):
        if item1 == item2:
          continue
        # æ–‡ç« ç‚¹å‡»é¡ºåº: é¡ºåºåå¥½ï¼Œsim(i, j) != sim(j, i)
        loc_alpha = 1.0 if loc1 > loc2 else 0.7
        # ä½ç½®æƒé‡: ç›¸é‚»ï¼ˆé—´è·=1ï¼‰æƒé‡æœ€å¤§ 1ï¼Œé—´è·è¶Šè¿œè¶Šå°
        loc_weight = loc_alpha * (0.9 ** (np.abs(loc1 - loc2) - 1))
        # æ—¶é—´æƒé‡
        click_time_weight = np.exp(0.7 ** np.abs(time1 - time2))
        # æ–‡ç« åˆ›å»ºæ—¶é—´æƒé‡
        created_time_weight = np.exp(0.7 ** np.abs(item_created_time_dict[item1] - item_created_time_dict[item2]))

        # item1 -> item2
        i2i_sim[item1].setdefault(item2, 0)
        # èåˆï¼Œç„¶ååšå½’ä¸€åŒ–
        i2i_sim[item1][item2] += loc_weight * click_time_weight * created_time_weight / math.log(len(item_time_list) + 1)

  i2i_sim_ = i2i_sim.copy()
  for i, related_items in i2i_sim.items():
      for j, wij in related_items.items():
          i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])

  # å°†å¾—åˆ°çš„ç›¸ä¼¼æ€§çŸ©é˜µä¿å­˜åˆ°æœ¬åœ°
  pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))

  return i2i_sim_

i2i_sim = itemcf_sim(all_click_df, item_created_time_dict)

# Cell 33
def get_user_activate_degree_dict(all_click_df):
  cnt = all_click_df.groupby('user_id')['click_article_id'].count().reset_index(name='click_cnt')
  mm = MinMaxScaler()
  cnt['activity_score'] = mm.fit_transform(cnt[['click_cnt']])
  user_activate_degree_dict = dict(zip(cnt['user_id'], cnt['activity_score']))

  return user_activate_degree_dict


# Cell 34
def usercf_sim(all_click_df, user_activate_degree_dict):
  item_user_time_dict = get_item_user_time(all_click_df)

  u2u_sim = {}
  user_cnt = defaultdict(int)
  for item, user_time_list in tqdm(item_user_time_dict.items()):
    for u, click_time in user_time_list:
      user_cnt[u] += 1
      u2u_sim.setdefault(u, {})

      for v, click_time in user_time_list:
        u2u_sim[u].setdefault(v, 0)
        if u == v:
          continue

        # ç”¨æˆ·æ´»è·ƒåº¦å·®å€¼æœ‰å…³
        activate_weight = 100 * 0.5 * (user_activate_degree_dict[u] + user_activate_degree_dict[v])
        u2u_sim[u][v] += activate_weight / math.log(len(user_time_list) + 1)

  u2u_sim_ = u2u_sim.copy()
  for u, related_users in u2u_sim.items():
    for v, wij in related_users.items():
      u2u_sim_[u][v] = wij / math.sqrt(user_cnt[u] * user_cnt[v])

  # save
  pickle.dump(u2u_sim_, open(save_path + 'usercf_u2u_sim.pkl', 'wb'))

  return u2u_sim_

sample = get_all_click_sample(data_path)
user_activate_degree_dict = get_user_activate_degree_dict(sample)
u2u_sim = usercf_sim(sample, user_activate_degree_dict)

# Cell 36
def embedding_sim(click_df, item_emb_dict, save_path, topk):
  # click_df: è®¡ç®—å“ªäº›ç‰©å“çš„ç›¸ä¼¼åº¦
  # item_emb_dfï¼šç‰©å“çš„ embedding
  # topk: æ¯ä¸ªç‰©å“è®¡ç®— topk ç›¸ä¼¼

  # å»ºç«‹æ–‡ç« ç´¢å¼•å’Œæ–‡ç« idçš„å­—å…¸æ˜ å°„
  ids = np.array(list(item_emb_dict.keys()))
  item_emb_dict = np.ascontiguousarray(np.stack([item_emb_dict[i] for i in ids]).astype(np.float32))
  item_idx_2_rawid_dict = dict(enumerate(ids))

  # å»ºç«‹faissç´¢å¼•
  item_index = faiss.IndexFlatIP(item_emb_dict.shape[1])
  item_index.add(item_emb_dict)

  # ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼Œç»™æ¯ä¸ªç´¢å¼•ä½ç½®ä¸Šçš„å‘é‡è¿”å›topkä¸ªitemä»¥åŠç›¸ä¼¼åº¦
  sim, idx = item_index.search(item_emb_dict, topk) # è¿”å›çš„æ˜¯åˆ—è¡¨

  # å°†å‘é‡æ£€ç´¢çš„ç»“æœï¼Œä¿å­˜ä¸ºåŸå§‹ id çš„å¯¹åº”å…³ç³»
  item_sim_dict = collections.defaultdict(dict)
  for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(item_emb_dict)), sim, idx)):
    target_raw_id = item_idx_2_rawid_dict[target_idx]
    # ä»1å¼€å§‹æ˜¯ä¸ºäº†å»æ‰å•†å“æœ¬èº«, æ‰€ä»¥æœ€ç»ˆè·å¾—çš„ç›¸ä¼¼å•†å“åªæœ‰topk-1
    for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]):
        rele_raw_id = item_idx_2_rawid_dict[rele_idx]
        item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value

  pickle.dump(item_sim_dict, open(save_path + 'emb_i2i_sim.pkl', 'wb'))

  return item_sim_dict

# Cell 37
emb_i2i_sim = embedding_sim(all_click_df, item_emb_dict, save_path, topk=10) # topkå¯ä»¥è‡ªè¡Œè®¾ç½®

# Cell 40
# è·å–åŒå¡”å¬å›æ—¶çš„è®­ç»ƒéªŒè¯æ•°æ®
# negsampleæŒ‡çš„æ˜¯é€šè¿‡æ»‘çª—æ„å»ºæ ·æœ¬çš„æ—¶å€™ï¼Œè´Ÿæ ·æœ¬çš„æ•°é‡
def gen_data_set(data, negsample=0):
    # æŒ‰æ—¶é—´/ç‚¹å‡»é¡ºåºæ’åº
    data.sort_values("click_timestamp", inplace=True)
    # è·å–æ‰€æœ‰æ–‡ç«  id
    item_ids = data['click_article_id'].unique()

    # å­˜æ”¾è®­ç»ƒé›†
    train_set = []
    # å­˜æ”¾æµ‹è¯•é›†
    test_set = []
    # æŒ‰ç”¨æˆ·åˆ†ç»„ï¼Œé€ä¸ªç”¨æˆ·å¤„ç†
    for reviewerID, hist in tqdm(data.groupby('user_id'), disable=not logger.isEnabledFor(logging.DEBUG)):
        # æ­£æ ·æœ¬ï¼šç”¨æˆ·ç‚¹å‡»è¿‡çš„æ–‡ç« 
        pos_list = hist['click_article_id'].tolist()

        # éœ€è¦åšè´Ÿé‡‡æ ·
        if negsample > 0:
            # ç”¨æˆ·æ²¡æœ‰ç‚¹å‡»è¿‡çš„æ–‡ç« åˆ—è¡¨
            candidate_set = list(set(item_ids) - set(pos_list))
            # ä»ç”¨æˆ·æ²¡æœ‰ç‚¹å‡»è¿‡çš„æ–‡ç« é‡ŒæŠ½é€‰è´Ÿæ ·æœ¬ï¼Œæ ¹æ®æ­£æ ·æœ¬çš„æ•°é‡ï¼ŒæŠ½å–æ ‡å‡†æ˜¯æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº” negsample ä¸ªè´Ÿæ ·æœ¬
            neg_list = np.random.choice(candidate_set,size=len(pos_list)*negsample,replace=True)  # å¯¹äºæ¯ä¸ªæ­£æ ·æœ¬ï¼Œé€‰æ‹©nä¸ªè´Ÿæ ·æœ¬

        # å¦‚æœç”¨æˆ·åªç‚¹å‡»è¿‡ä¸€ç¯‡æ–‡ç« ï¼Œåˆ™è¯¥æ–‡ç« éœ€è¦ä¹Ÿæ”¾å…¥è®­ç»ƒé›†ï¼Œå¦åˆ™ä¼šæœ‰ä¿¡æ¯ç¼ºå¤±
        if len(pos_list) == 1:
            train_set.append((reviewerID, [pos_list[0]], pos_list[0],1,len(pos_list)))
            test_set.append((reviewerID, [pos_list[0]], pos_list[0],1,len(pos_list)))

        # æ»‘çª—æ„é€ æ­£è´Ÿæ ·æœ¬ï¼Œç‚¹å‡»æ¬¡æ•°å¤§äº 1ï¼›å› ä¸ºç”¨æˆ·ç‚¹å‡»æ˜¯ä¸€ä¸ªæ—¶é—´åºåˆ—ï¼Œä»ç”¨æˆ·ç‚¹å‡»çš„åºåˆ—ä¸­ï¼Œæ„å»ºå¤šä¸ªæ­£æ ·æœ¬
        '''
          ç”¨æˆ·ç‚¹å‡» [A, B, C, D]
          ä¸æ»‘çª—: å†å²=[A,B,C] â†’ é¢„æµ‹ D
          æ»‘çª—ï¼š
            å†å²=[A]   â†’ é¢„æµ‹ B
            å†å²=[A,B] â†’ é¢„æµ‹ C
            å†å²=[A,B,C] â†’ é¢„æµ‹ D
        '''
        for i in range(1, len(pos_list)):
            # hist: å†å²ï¼Œå‰ i ç¯‡
            # pos_itemï¼šé¢„æµ‹ç›®æ ‡ï¼Œç¬¬ i ç¯‡

            hist = pos_list[:i]

            # ä¸æ˜¯æœ€åä¸€æ¬¡ç‚¹å‡»
            if i != len(pos_list) - 1:
                # æ·»åŠ æ­£æ ·æœ¬
                train_set.append((reviewerID, hist[::-1], pos_list[i], 1, len(hist[::-1])))  # æ­£æ ·æœ¬ [user_id, his_item, pos_item, label, len(his_item)]
                # æ·»åŠ  n ä¸ªè´Ÿæ ·æœ¬
                for negi in range(negsample):
                    train_set.append((reviewerID, hist[::-1], neg_list[i*negsample+negi], 0,len(hist[::-1]))) # è´Ÿæ ·æœ¬ [user_id, his_item, neg_item, label, len(his_item)]
            # æœ€åä¸€æ¬¡ç‚¹å‡»ï¼Œæµ‹è¯•é›†
            else:
                test_set.append((reviewerID, hist[::-1], pos_list[i],1,len(hist[::-1])))

    # æ‰“ä¹±æ ·æœ¬é¡ºåº
    random.shuffle(train_set)
    random.shuffle(test_set)

    return train_set, test_set

# å°†è¾“å…¥çš„æ•°æ®è¿›è¡Œpaddingï¼Œä½¿å¾—åºåˆ—ç‰¹å¾çš„é•¿åº¦éƒ½ä¸€è‡´
def gen_model_input(train_set,user_profile,seq_max_len):

    train_uid = np.array([line[0] for line in train_set])
    train_seq = [line[1] for line in train_set]
    train_iid = np.array([line[2] for line in train_set])
    train_label = np.array([line[3] for line in train_set])
    train_hist_len = np.array([line[4] for line in train_set])

    # å› ä¸ºæ¯ä¸ªç”¨æˆ·å†å²ç‚¹å‡»æ•°ä¸ä¸€æ ·ï¼Œéœ€è¦ç»Ÿä¸€é•¿åº¦ï¼ŒçŸ­çš„è¡¥0ï¼Œé•¿çš„æˆªæ–­ã€‚
    train_seq_pad = pad_sequences(train_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)
    # ç»„è£…ä¸ºå­—å…¸
    train_model_input = {"user_id": train_uid, "click_article_id": train_iid, "hist_article_id": train_seq_pad,
                         "hist_len": train_hist_len}
    # è¿”å›è¾“å…¥ç‰¹å¾ï¼Œå¯¹åº”æ ‡ç­¾
    return train_model_input, train_label

# Cell 42
# funrec youtubeDNNå¬å›
def youtubednn_u2i_dict(data, topk=20):
    """
    ä½¿ç”¨ FunRec çš„ YouTubeDNN ä¸¤å¡”æ¨¡å‹è¿›è¡Œå¬å›ï¼Œä¿æŒä¸å½“å‰é€»è¾‘ä¸€è‡´çš„é¢„å¤„ç†ï¼š
    - æ ‡ç­¾/ç›®æ ‡ä¸ºæ­£æ ·æœ¬é‡‡æ ·ï¼ˆsampled softmax å†…éƒ¨ä½¿ç”¨ item_id ä½œä¸º labelï¼‰
    - é€šè¿‡æ»‘çª—æ„é€ è®­ç»ƒ/æµ‹è¯•æ ·æœ¬ï¼Œä½¿ç”¨æœ€è¿‘åºåˆ—ä½œä¸ºæµ‹è¯•
    - å†å²åºåˆ—é•¿åº¦å›ºå®šä¸º SEQ_LENï¼Œå¹¶åš post-padding
    - è®­ç»ƒå®Œæˆåæå– user/item embeddingï¼Œä½¿ç”¨ FAISS åŸºäºå†…ç§¯åš TopK è¿‘é‚»å¬å›
    - è¿”å› {user_raw_id: [(item_raw_id, score), ...]} çš„å¬å›ç»“æœå­—å…¸
    """
    import sys
    import numpy as np
    import pickle
    from tqdm import tqdm
    from sklearn.preprocessing import LabelEncoder

    from funrec.features.feature_column import FeatureColumn
    from funrec.training.trainer import train_model

    # å†…è”é…ç½®ï¼ˆå‚è€ƒ config_youtubednn.yamlï¼Œå¹¶é€‚é…å½“å‰æ•°æ®åˆ—åï¼‰
    SEQ_LEN = 30
    emb_dim = 16
    neg_sample = 20
    dnn_units = [32]
    label_name = 'click_article_id'

    # æ‹·è´å¹¶åšç±»åˆ«ç¼–ç ï¼ˆä¸ç°æœ‰é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
    df = data.copy()
    user_profile_raw = df[["user_id"]].drop_duplicates('user_id')
    item_profile_raw = df[["click_article_id"]].drop_duplicates('click_article_id')

    encoders = {}
    feature_max_idx = {}
    for col in ["user_id", "click_article_id"]:
        lbe = LabelEncoder()
        df[col] = lbe.fit_transform(df[col])
        encoders[col] = lbe
        feature_max_idx[col] = int(df[col].max()) + 1

    # ç”»åƒï¼ˆä»…ç”¨äº id å›é€€æ˜ å°„ï¼‰
    user_profile = df[["user_id"]].drop_duplicates('user_id')
    item_profile = df[["click_article_id"]].drop_duplicates('click_article_id')
    user_index_2_rawid = dict(zip(user_profile['user_id'], user_profile_raw['user_id']))
    item_index_2_rawid = dict(zip(item_profile['click_article_id'], item_profile_raw['click_article_id']))

    # æŒ‰å½“å‰é€»è¾‘æ„é€ è®­ç»ƒ/æµ‹è¯•æ ·æœ¬
    train_set, test_set = gen_data_set(df, 0)
    train_model_input, _ = gen_model_input(train_set, user_profile, SEQ_LEN)
    test_model_input, _ = gen_model_input(test_set, user_profile, SEQ_LEN)

    # ä»…ä¿ç•™æ¨¡å‹å®é™…éœ€è¦çš„è¾“å…¥é”®
    input_keys = ['user_id', 'click_article_id', 'hist_article_id']
    train_X = {k: np.asarray(train_model_input[k], dtype=np.int32) for k in input_keys}
    test_X = {k: np.asarray(test_model_input[k], dtype=np.int32) for k in input_keys}

    # æ‰‹åŠ¨å®šä¹‰ç‰¹å¾åˆ—ï¼ˆä¸ä¾èµ–å¤–éƒ¨æ•°æ®å­—å…¸ï¼‰
    feature_columns = [
        FeatureColumn(name='user_id', group=['user_dnn'], type='sparse', vocab_size=feature_max_idx['user_id'], emb_dim=emb_dim),
        FeatureColumn(name='click_article_id', group=['target_item'], type='sparse', vocab_size=feature_max_idx['click_article_id'], emb_dim=emb_dim),
        FeatureColumn(name='hist_article_id', emb_name='click_article_id', group=['raw_hist_seq'], type='varlen_sparse', max_len=SEQ_LEN, combiner='mean', emb_dim=emb_dim, vocab_size=feature_max_idx['click_article_id']),
    ]

    # ç»„è£… processed_dataï¼ˆä¸ FunRec è®­ç»ƒå™¨æœŸæœ›çš„ç»“æ„ä¸€è‡´ï¼‰
    processed_data = {
        'train': {
            'features': train_X,
            'labels': None  # ç”± positive_sampling_labels è§„åˆ™å†…éƒ¨æ›¿æ¢ä¸ºå…¨ 1
        },
        'test': {
            'features': test_X,
            'labels': None,
            'eval_data': {}
        },
        'all_items': {
            'click_article_id': np.arange(feature_max_idx['click_article_id'], dtype=np.int32)
        },
        'feature_dict': {
            'user_id': feature_max_idx['user_id'],
            'click_article_id': feature_max_idx['click_article_id']
        }
    }

    # è®­ç»ƒé…ç½®ï¼ˆå†…è”ï¼‰
    training_config = {
        'build_function': 'funrec.models.youtubednn.build_youtubednn_model',
        'data_preprocessing': [
            {'type': 'positive_sampling_labels'}
        ],
        'model_params': {
            'emb_dim': emb_dim,
            'neg_sample': neg_sample,
            'dnn_units': dnn_units,
            'label_name': label_name
        },
        'optimizer': 'adam',
        'optimizer_params': {
            'learning_rate': 1e-4
        },
        'loss': 'sampledsoftmaxloss',
        'batch_size': 128,
        'epochs': 5,
        'verbose': 0
    }

    # è®­ç»ƒæ¨¡å‹ï¼ˆè¿”å› main_model, user_model, item_modelï¼‰
    model, user_model, item_model = train_model(training_config, feature_columns, processed_data)

    # æå– embedding
    user_inputs_for_pred = {k: test_X[k] for k in ['user_id', 'hist_article_id']}
    user_embs = user_model.predict(user_inputs_for_pred, batch_size=2 ** 12, verbose=0)
    item_embs = item_model.predict(processed_data['all_items'], batch_size=2 ** 12, verbose=0)

    # å½’ä¸€åŒ–ï¼ˆä¸ç°æœ‰é€»è¾‘ä¸€è‡´ï¼‰
    user_embs = user_embs / np.linalg.norm(user_embs, axis=1, keepdims=True)
    item_embs = item_embs / np.linalg.norm(item_embs, axis=1, keepdims=True)

    # ä¿å­˜ embeddingï¼ˆä¸ç°æœ‰é€»è¾‘ä¸€è‡´ï¼Œæ³¨æ„ id å›é€€ï¼‰
    raw_user_id_emb_dict = {user_index_2_rawid[k]: v for k, v in zip(test_X['user_id'], user_embs)}
    raw_item_id_emb_dict = {item_index_2_rawid[k]: v for k, v in zip(processed_data['all_items']['click_article_id'], item_embs)}
    pickle.dump(raw_user_id_emb_dict, open(save_path / 'user_youtube_emb.pkl', 'wb'))
    pickle.dump(raw_item_id_emb_dict, open(save_path / 'item_youtube_emb.pkl', 'wb'))

    # ä½¿ç”¨ FAISS åšå‘é‡æ£€ç´¢å¬å›
    index = faiss.IndexFlatIP(emb_dim)
    index.add(item_embs.astype(np.float32))
    sim, idx = index.search(np.ascontiguousarray(user_embs.astype(np.float32)), topk)

    user_recall_items_dict = defaultdict(dict)
    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(test_X['user_id'], sim, idx), disable=not logger.isEnabledFor(logging.DEBUG)):
        target_raw_id = user_index_2_rawid[int(target_idx)]
        # ä» 1 å¼€å§‹å»æ‰æœ€ç›¸ä¼¼çš„ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸ä¸ºæœ¬èº«æˆ–æè¿‘é‚»ï¼‰
        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]):
            rele_raw_id = item_index_2_rawid[int(rele_idx)]
            user_recall_items_dict[target_raw_id][rele_raw_id] = user_recall_items_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + float(sim_value)

    # æ’åºå¹¶ä¿å­˜
    user_recall_items_dict = {k: sorted(v.items(), key=lambda x: x[1], reverse=True) for k, v in user_recall_items_dict.items()}
    pickle.dump(user_recall_items_dict, open(save_path / 'youtube_u2i_dict.pkl', 'wb'))
    return user_recall_items_dict

# Cell 43
# ç”±äºè¿™é‡Œéœ€è¦åšå¬å›è¯„ä¼°ï¼Œæ‰€ä»¥è®²è®­ç»ƒé›†ä¸­çš„æœ€åä¸€æ¬¡ç‚¹å‡»éƒ½æå–äº†å‡ºæ¥
if not metric_recall:
    user_multi_recall_dict['youtubednn_recall'] = youtubednn_u2i_dict(all_click_df, topk=20)
else:
    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)
    user_multi_recall_dict['youtubednn_recall'] = youtubednn_u2i_dict(trn_hist_click_df, topk=20)
    # å¬å›æ•ˆæœè¯„ä¼°
    metrics_recall(user_multi_recall_dict['youtubednn_recall'], trn_last_click_df, topk=20)

# Cell 45
# åŸºäºå•†å“çš„å¬å›i2i
def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim):
    """
        åŸºäºæ–‡ç« ååŒè¿‡æ»¤çš„å¬å›
        :param user_id: ç”¨æˆ·id
        :param user_item_time_dict: å­—å…¸, æ ¹æ®ç‚¹å‡»æ—¶é—´è·å–ç”¨æˆ·çš„ç‚¹å‡»æ–‡ç« åºåˆ—   {user1: {item1: time1, item2: time2..}...}
        :param i2i_sim: å­—å…¸ï¼Œæ–‡ç« ç›¸ä¼¼æ€§çŸ©é˜µ
        :param sim_item_topk: æ•´æ•°ï¼Œ é€‰æ‹©ä¸å½“å‰æ–‡ç« æœ€ç›¸ä¼¼çš„å‰kç¯‡æ–‡ç« 
        :param recall_item_num: æ•´æ•°ï¼Œ æœ€åçš„å¬å›æ–‡ç« æ•°é‡
        :param item_topk_click: åˆ—è¡¨ï¼Œç‚¹å‡»æ¬¡æ•°æœ€å¤šçš„æ–‡ç« åˆ—è¡¨ï¼Œç”¨æˆ·å¬å›è¡¥å…¨
        :param emb_i2i_sim: å­—å…¸åŸºäºå†…å®¹embeddingç®—çš„æ–‡ç« ç›¸ä¼¼çŸ©é˜µ

        return: å¬å›çš„æ–‡ç« åˆ—è¡¨ {item1:score1, item2: score2...}

    """
    # è·å–ç”¨æˆ·å†å²äº¤äº’çš„æ–‡ç« 
    user_hist_items = user_item_time_dict[user_id]

    item_rank = {}
    for loc, (i, click_time) in enumerate(user_hist_items):
        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:
            if j in user_hist_items:
                continue

            # æ–‡ç« åˆ›å»ºæ—¶é—´å·®æƒé‡
            created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))
            # ç›¸ä¼¼æ–‡ç« å’Œå†å²ç‚¹å‡»æ–‡ç« åºåˆ—ä¸­å†å²æ–‡ç« æ‰€åœ¨çš„ä½ç½®æƒé‡
            loc_weight = (0.9 ** (len(user_hist_items) - loc))

            content_weight = 1.0
            if emb_i2i_sim.get(i, {}).get(j, None) is not None:
                content_weight += emb_i2i_sim[i][j]
            if emb_i2i_sim.get(j, {}).get(i, None) is not None:
                content_weight += emb_i2i_sim[j][i]

            item_rank.setdefault(j, 0)
            item_rank[j] += created_time_weight * loc_weight * content_weight * wij

    # ä¸è¶³10ä¸ªï¼Œç”¨çƒ­é—¨å•†å“è¡¥å…¨
    if len(item_rank) < recall_item_num:
        for i, item in enumerate(item_topk_click):
            if item in item_rank.items(): # å¡«å……çš„itemåº”è¯¥ä¸åœ¨åŸæ¥çš„åˆ—è¡¨ä¸­
                continue
            item_rank[item] = - i - 100 # éšä¾¿ç»™ä¸ªè´Ÿæ•°å°±è¡Œ
            if len(item_rank) == recall_item_num:
                break

    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]

    return item_rank

# Cell 46
# å…ˆè¿›è¡Œitemcfå¬å›, ä¸ºäº†å¬å›è¯„ä¼°ï¼Œæ‰€ä»¥æå–æœ€åä¸€æ¬¡ç‚¹å‡»

if metric_recall:
    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)
else:
    trn_hist_click_df = all_click_df

user_recall_items_dict = defaultdict(dict)
user_item_time_dict = get_user_item_time(trn_hist_click_df)

i2i_sim = pickle.load(open(save_path / 'itemcf_i2i_sim.pkl', 'rb'))
emb_i2i_sim = pickle.load(open(save_path / 'emb_i2i_sim.pkl', 'rb'))

sim_item_topk = 20
recall_item_num = 10
item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)

for user in tqdm(trn_hist_click_df['user_id'].unique(), disable=not logger.isEnabledFor(logging.DEBUG)):
    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, \
                                                        i2i_sim, sim_item_topk, recall_item_num, \
                                                        item_topk_click, item_created_time_dict, emb_i2i_sim)

user_multi_recall_dict['itemcf_sim_itemcf_recall'] = user_recall_items_dict
pickle.dump(user_multi_recall_dict['itemcf_sim_itemcf_recall'], open(save_path / 'itemcf_recall_dict.pkl', 'wb'))

if metric_recall:
    # å¬å›æ•ˆæœè¯„ä¼°
    metrics_recall(user_multi_recall_dict['itemcf_sim_itemcf_recall'], trn_last_click_df, topk=recall_item_num)

# Cell 48
# è¿™é‡Œæ˜¯ä¸ºäº†å¬å›è¯„ä¼°ï¼Œæ‰€ä»¥æå–æœ€åä¸€æ¬¡ç‚¹å‡»
if metric_recall:
    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)
else:
    trn_hist_click_df = all_click_df

user_recall_items_dict = defaultdict(dict)
user_item_time_dict = get_user_item_time(trn_hist_click_df)
i2i_sim = pickle.load(open(save_path / 'emb_i2i_sim.pkl','rb'))

sim_item_topk = 20
recall_item_num = 10

item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)

for user in tqdm(trn_hist_click_df['user_id'].unique(), disable=not logger.isEnabledFor(logging.DEBUG)):
    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk,
                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)

user_multi_recall_dict['embedding_sim_item_recall'] = user_recall_items_dict
pickle.dump(user_multi_recall_dict['embedding_sim_item_recall'], open(save_path / 'embedding_sim_item_recall.pkl', 'wb'))

if metric_recall:
    # å¬å›æ•ˆæœè¯„ä¼°
    metrics_recall(user_multi_recall_dict['embedding_sim_item_recall'], trn_last_click_df, topk=recall_item_num)

# Cell 50
# åŸºäºç”¨æˆ·çš„å¬å› u2u2i
def user_based_recommend(user_id, user_item_time_dict, u2u_sim, sim_user_topk, recall_item_num,
                         item_topk_click, item_created_time_dict, emb_i2i_sim):
    """
        åŸºäºæ–‡ç« ååŒè¿‡æ»¤çš„å¬å›
        :param user_id: ç”¨æˆ·id
        :param user_item_time_dict: å­—å…¸, æ ¹æ®ç‚¹å‡»æ—¶é—´è·å–ç”¨æˆ·çš„ç‚¹å‡»æ–‡ç« åºåˆ—   {user1: {item1: time1, item2: time2..}...}
        :param u2u_sim: å­—å…¸ï¼Œæ–‡ç« ç›¸ä¼¼æ€§çŸ©é˜µ
        :param sim_user_topk: æ•´æ•°ï¼Œ é€‰æ‹©ä¸å½“å‰ç”¨æˆ·æœ€ç›¸ä¼¼çš„å‰kä¸ªç”¨æˆ·
        :param recall_item_num: æ•´æ•°ï¼Œ æœ€åçš„å¬å›æ–‡ç« æ•°é‡
        :param item_topk_click: åˆ—è¡¨ï¼Œç‚¹å‡»æ¬¡æ•°æœ€å¤šçš„æ–‡ç« åˆ—è¡¨ï¼Œç”¨æˆ·å¬å›è¡¥å…¨
        :param item_created_time_dict: æ–‡ç« åˆ›å»ºæ—¶é—´åˆ—è¡¨
        :param emb_i2i_sim: å­—å…¸åŸºäºå†…å®¹embeddingç®—çš„æ–‡ç« ç›¸ä¼¼çŸ©é˜µ

        return: å¬å›çš„æ–‡ç« åˆ—è¡¨ {item1:score1, item2: score2...}
    """
    # å†å²äº¤äº’
    user_item_time_list = user_item_time_dict[user_id]    # {item1: time1, item2: time2...}
    user_hist_items = set([i for i, t in user_item_time_list])   # å­˜åœ¨ä¸€ä¸ªç”¨æˆ·ä¸æŸç¯‡æ–‡ç« çš„å¤šæ¬¡äº¤äº’ï¼Œ è¿™é‡Œå¾—å»é‡

    items_rank = {}
    for sim_u, wuv in sorted(u2u_sim[user_id].items(), key=lambda x: x[1], reverse=True)[:sim_user_topk]:
        for i, click_time in user_item_time_dict[sim_u]:
            if i in user_hist_items:
                continue
            items_rank.setdefault(i, 0)

            loc_weight = 1.0
            content_weight = 1.0
            created_time_weight = 1.0

            # å½“å‰æ–‡ç« ä¸è¯¥ç”¨æˆ·çœ‹çš„å†å²æ–‡ç« è¿›è¡Œä¸€ä¸ªæƒé‡äº¤äº’
            for loc, (j, click_time) in enumerate(user_item_time_list):
                # ç‚¹å‡»æ—¶çš„ç›¸å¯¹ä½ç½®æƒé‡
                loc_weight += 0.9 ** (len(user_item_time_list) - loc)
                # å†…å®¹ç›¸ä¼¼æ€§æƒé‡
                if emb_i2i_sim.get(i, {}).get(j, None) is not None:
                    content_weight += emb_i2i_sim[i][j]
                if emb_i2i_sim.get(j, {}).get(i, None) is not None:
                    content_weight += emb_i2i_sim[j][i]

                # åˆ›å»ºæ—¶é—´å·®æƒé‡
                created_time_weight += np.exp(0.8 * np.abs(item_created_time_dict[i] - item_created_time_dict[j]))

            items_rank[i] += loc_weight * content_weight * created_time_weight * wuv

    # çƒ­åº¦è¡¥å…¨
    if len(items_rank) < recall_item_num:
        for i, item in enumerate(item_topk_click):
            if item in items_rank.items(): # å¡«å……çš„itemåº”è¯¥ä¸åœ¨åŸæ¥çš„åˆ—è¡¨ä¸­
                continue
            items_rank[item] = - i - 100 # éšä¾¿ç»™ä¸ªå¤æ•°å°±è¡Œ
            if len(items_rank) == recall_item_num:
                break

    items_rank = sorted(items_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]

    return items_rank

# Cell 51
# å®é™…å¬å›

# è¿™é‡Œæ˜¯ä¸ºäº†å¬å›è¯„ä¼°ï¼Œæ‰€ä»¥æå–æœ€åä¸€æ¬¡ç‚¹å‡»
# ç”±äºusercfä¸­è®¡ç®—userä¹‹é—´çš„ç›¸ä¼¼åº¦çš„è¿‡ç¨‹å¤ªè´¹å†…å­˜äº†ï¼Œå…¨é‡æ•°æ®è¿™é‡Œå°±æ²¡æœ‰è·‘ï¼Œè·‘äº†ä¸€ä¸ªé‡‡æ ·ä¹‹åçš„æ•°æ®
if metric_recall:
    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)
else:
    trn_hist_click_df = all_click_df

user_recall_items_dict = defaultdict(dict)
user_item_time_dict = get_user_item_time(trn_hist_click_df)

u2u_sim = pickle.load(open(save_path / 'usercf_u2u_sim.pkl', 'rb'))

sim_user_topk = 20
recall_item_num = 10
item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)

for user in tqdm(trn_hist_click_df['user_id'].unique(), disable=not logger.isEnabledFor(logging.DEBUG)):
    user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \
                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)

pickle.dump(user_recall_items_dict, open(save_path / 'usercf_u2u2i_recall.pkl', 'wb'))

if metric_recall:
    # å¬å›æ•ˆæœè¯„ä¼°
    metrics_recall(user_recall_items_dict, trn_last_click_df, topk=recall_item_num)

# Cell 53
# ä½¿ç”¨Embeddingçš„æ–¹å¼è·å–u2uçš„ç›¸ä¼¼æ€§çŸ©é˜µ
# topkæŒ‡çš„æ˜¯æ¯ä¸ªuser, faissæœç´¢åè¿”å›æœ€ç›¸ä¼¼çš„topkä¸ªuser
def u2u_embdding_sim(click_df, user_emb_dict, save_path, topk):

    user_list = []
    user_emb_list = []
    for user_id, user_emb in user_emb_dict.items():
        user_list.append(user_id)
        user_emb_list.append(user_emb)

    user_index_2_rawid_dict = {k: v for k, v in zip(range(len(user_list)), user_list)}

    user_emb_np = np.array(user_emb_list, dtype=np.float32)

    # å»ºç«‹faissç´¢å¼•
    user_index = faiss.IndexFlatIP(user_emb_np.shape[1])
    user_index.add(user_emb_np)
    # ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼Œç»™æ¯ä¸ªç´¢å¼•ä½ç½®ä¸Šçš„å‘é‡è¿”å›topkä¸ªitemä»¥åŠç›¸ä¼¼åº¦
    sim, idx = user_index.search(user_emb_np, topk) # è¿”å›çš„æ˜¯åˆ—è¡¨

    # å°†å‘é‡æ£€ç´¢çš„ç»“æœä¿å­˜æˆåŸå§‹idçš„å¯¹åº”å…³ç³»
    user_sim_dict = defaultdict(dict)
    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(user_emb_np)), sim, idx), disable=not logger.isEnabledFor(logging.DEBUG)):
        target_raw_id = user_index_2_rawid_dict[target_idx]
        # ä»1å¼€å§‹æ˜¯ä¸ºäº†å»æ‰å•†å“æœ¬èº«, æ‰€ä»¥æœ€ç»ˆè·å¾—çš„ç›¸ä¼¼å•†å“åªæœ‰topk-1
        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]):
            rele_raw_id = user_index_2_rawid_dict[rele_idx]
            user_sim_dict[target_raw_id][rele_raw_id] = user_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value

    # ä¿å­˜i2iç›¸ä¼¼åº¦çŸ©é˜µ
    pickle.dump(user_sim_dict, open(save_path / 'youtube_u2u_sim.pkl', 'wb'))
    return user_sim_dict

# Cell 54
# è¯»å–YoutubeDNNè¿‡ç¨‹ä¸­äº§ç”Ÿçš„user embedding, ç„¶åä½¿ç”¨faissè®¡ç®—ç”¨æˆ·ä¹‹é—´çš„ç›¸ä¼¼åº¦
# è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œè¿™é‡Œå¾—åˆ°çš„user embeddingå…¶å®å¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºYoutubeDNNä¸­ä½¿ç”¨çš„æ˜¯ç”¨æˆ·ç‚¹å‡»åºåˆ—æ¥è®­ç»ƒçš„user embedding,
# å¦‚æœåºåˆ—æ™®ééƒ½æ¯”è¾ƒçŸ­çš„è¯ï¼Œå…¶å®æ•ˆæœå¹¶ä¸æ˜¯å¾ˆå¥½
user_emb_dict = pickle.load(open(save_path / 'user_youtube_emb.pkl', 'rb'))
u2u_sim = u2u_embdding_sim(all_click_df, user_emb_dict, save_path, topk=10)

# Cell 55
# å®é™…å¬å›
# ä½¿ç”¨å¬å›è¯„ä¼°å‡½æ•°éªŒè¯å½“å‰å¬å›æ–¹å¼çš„æ•ˆæœ
if metric_recall:
    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)
else:
    trn_hist_click_df = all_click_df

user_recall_items_dict = defaultdict(dict)
user_item_time_dict = get_user_item_time(trn_hist_click_df)
u2u_sim = pickle.load(open(save_path / 'youtube_u2u_sim.pkl', 'rb'))

sim_user_topk = 20
recall_item_num = 10

item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)
for user in tqdm(trn_hist_click_df['user_id'].unique(), disable=not logger.isEnabledFor(logging.DEBUG)):
    user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \
                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)

user_multi_recall_dict['youtubednn_usercf_recall'] = user_recall_items_dict
pickle.dump(user_multi_recall_dict['youtubednn_usercf_recall'], open(save_path / 'youtubednn_usercf_recall.pkl', 'wb'))

if metric_recall:
    # å¬å›æ•ˆæœè¯„ä¼°
    metrics_recall(user_multi_recall_dict['youtubednn_usercf_recall'], trn_last_click_df, topk=recall_item_num)

# Cell 57
# å…ˆè¿›è¡Œitemcfå¬å›ï¼Œè¿™é‡Œä¸éœ€è¦åšå¬å›è¯„ä¼°ï¼Œè¿™é‡Œåªæ˜¯ä¸€ç§ç­–ç•¥
trn_hist_click_df = all_click_df

user_recall_items_dict = defaultdict(dict)
user_item_time_dict = get_user_item_time(trn_hist_click_df)
i2i_sim = pickle.load(open(save_path / 'emb_i2i_sim.pkl','rb'))

sim_item_topk = 150
recall_item_num = 100 # ç¨å¾®å¬å›å¤šä¸€ç‚¹æ–‡ç« ï¼Œä¾¿äºåç»­çš„è§„åˆ™ç­›é€‰

item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)
for user in tqdm(trn_hist_click_df['user_id'].unique(), disable=not logger.isEnabledFor(logging.DEBUG)):
    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk,
                                                        recall_item_num, item_topk_click,item_created_time_dict, emb_i2i_sim)
pickle.dump(user_recall_items_dict, open(save_path / 'cold_start_items_raw_dict.pkl', 'wb'))

# Cell 58
# åŸºäºè§„åˆ™è¿›è¡Œæ–‡ç« è¿‡æ»¤
# ä¿ç•™æ–‡ç« ä¸»é¢˜ä¸ç”¨æˆ·å†å²æµè§ˆä¸»é¢˜ç›¸ä¼¼çš„æ–‡ç« 
# ä¿ç•™æ–‡ç« å­—æ•°ä¸ç”¨æˆ·å†å²æµè§ˆæ–‡ç« å­—æ•°ç›¸å·®ä¸å¤§çš„æ–‡ç« 
# ä¿ç•™æœ€åä¸€æ¬¡ç‚¹å‡»å½“å¤©çš„æ–‡ç« 
# æŒ‰ç…§ç›¸ä¼¼åº¦è¿”å›æœ€ç»ˆçš„ç»“æœ

def get_click_article_ids_set(all_click_df):
    return set(all_click_df.click_article_id.values)

def cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \
                     user_last_item_created_time_dict, item_type_dict, item_words_dict,
                     item_created_time_dict, click_article_ids_set, recall_item_num):
    """
        å†·å¯åŠ¨çš„æƒ…å†µä¸‹å¬å›ä¸€äº›æ–‡ç« 
        :param user_recall_items_dict: åŸºäºå†…å®¹embeddingç›¸ä¼¼æ€§å¬å›æ¥çš„å¾ˆå¤šæ–‡ç« ï¼Œ å­—å…¸ï¼Œ {user1: [item1, item2, ..], }
        :param user_hist_item_typs_dict: å­—å…¸ï¼Œ ç”¨æˆ·ç‚¹å‡»çš„æ–‡ç« çš„ä¸»é¢˜æ˜ å°„
        :param user_hist_item_words_dict: å­—å…¸ï¼Œ ç”¨æˆ·ç‚¹å‡»çš„å†å²æ–‡ç« çš„å­—æ•°æ˜ å°„
        :param user_last_item_created_time_idct: å­—å…¸ï¼Œç”¨æˆ·ç‚¹å‡»çš„å†å²æ–‡ç« åˆ›å»ºæ—¶é—´æ˜ å°„
        :param item_tpye_idct: å­—å…¸ï¼Œæ–‡ç« ä¸»é¢˜æ˜ å°„
        :param item_words_dict: å­—å…¸ï¼Œæ–‡ç« å­—æ•°æ˜ å°„
        :param item_created_time_dict: å­—å…¸ï¼Œ æ–‡ç« åˆ›å»ºæ—¶é—´æ˜ å°„
        :param click_article_ids_set: é›†åˆï¼Œç”¨æˆ·ç‚¹å‡»è¿‡å¾—æ–‡ç« , ä¹Ÿå°±æ˜¯æ—¥å¿—é‡Œé¢å‡ºç°è¿‡çš„æ–‡ç« 
        :param recall_item_num: å¬å›æ–‡ç« çš„æ•°é‡ï¼Œ è¿™ä¸ªæŒ‡çš„æ˜¯æ²¡æœ‰å‡ºç°åœ¨æ—¥å¿—é‡Œé¢çš„æ–‡ç« æ•°é‡
    """

    cold_start_user_items_dict = {}
    for user, item_list in tqdm(user_recall_items_dict.items(), disable=not logger.isEnabledFor(logging.DEBUG)):
        cold_start_user_items_dict.setdefault(user, [])
        for item, score in item_list:
            # è·å–å†å²æ–‡ç« ä¿¡æ¯
            hist_item_type_set = user_hist_item_typs_dict[user]
            hist_mean_words = user_hist_item_words_dict[user]
            hist_last_item_created_time = user_last_item_created_time_dict[user]
            hist_last_item_created_time = datetime.fromtimestamp(hist_last_item_created_time)

            # è·å–å½“å‰å¬å›æ–‡ç« çš„ä¿¡æ¯
            curr_item_type = item_type_dict[item]
            curr_item_words = item_words_dict[item]
            curr_item_created_time = item_created_time_dict[item]
            curr_item_created_time = datetime.fromtimestamp(curr_item_created_time)

            # é¦–å…ˆï¼Œæ–‡ç« ä¸èƒ½å‡ºç°åœ¨ç”¨æˆ·çš„å†å²ç‚¹å‡»ä¸­ï¼Œ ç„¶åæ ¹æ®æ–‡ç« ä¸»é¢˜ï¼Œæ–‡ç« å•è¯æ•°ï¼Œæ–‡ç« åˆ›å»ºæ—¶é—´è¿›è¡Œç­›é€‰
            if curr_item_type not in hist_item_type_set or \
                item in click_article_ids_set or \
                abs(curr_item_words - hist_mean_words) > 200 or \
                abs((curr_item_created_time - hist_last_item_created_time).days) > 90:
                continue

            cold_start_user_items_dict[user].append((item, score))      # {user1: [(item1, score1), (item2, score2)..]...}

    # éœ€è¦æ§åˆ¶ä¸€ä¸‹å†·å¯åŠ¨å¬å›çš„æ•°é‡
    cold_start_user_items_dict = {k: sorted(v, key=lambda x:x[1], reverse=True)[:recall_item_num] \
                                  for k, v in cold_start_user_items_dict.items()}

    pickle.dump(cold_start_user_items_dict, open(save_path / 'cold_start_user_items_dict.pkl', 'wb'))

    return cold_start_user_items_dict

# Cell 59
all_click_df_ = all_click_df.copy()
all_click_df_ = all_click_df_.merge(item_info_df, how='left', on='click_article_id')
user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict = get_user_hist_item_info_dict(all_click_df_)
click_article_ids_set = get_click_article_ids_set(all_click_df)
# éœ€è¦æ³¨æ„çš„æ˜¯
# è¿™é‡Œä½¿ç”¨äº†å¾ˆå¤šè§„åˆ™æ¥ç­›é€‰å†·å¯åŠ¨çš„æ–‡ç« ï¼Œæ‰€ä»¥å‰é¢å†å¬å›çš„é˜¶æ®µå°±åº”è¯¥å°½å¯èƒ½çš„å¤šå¬å›ä¸€äº›æ–‡ç« ï¼Œå¦åˆ™å¾ˆå®¹æ˜“è¢«åˆ æ‰
cold_start_user_items_dict = cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \
                                              user_last_item_created_time_dict, item_type_dict, item_words_dict, \
                                              item_created_time_dict, click_article_ids_set, recall_item_num)

user_multi_recall_dict['cold_start_recall'] = cold_start_user_items_dict

# Cell 61
def combine_recall_results(user_multi_recall_dict, weight_dict=None, topk=25):
    final_recall_items_dict = {}

    # å¯¹æ¯ä¸€ç§å¬å›ç»“æœæŒ‰ç…§ç”¨æˆ·è¿›è¡Œå½’ä¸€åŒ–ï¼Œæ–¹ä¾¿åé¢å¤šç§å¬å›ç»“æœï¼Œç›¸åŒç”¨æˆ·çš„ç‰©å“ä¹‹é—´æƒé‡ç›¸åŠ 
    def norm_user_recall_items_sim(sorted_item_list):
        # å¦‚æœå†·å¯åŠ¨ä¸­æ²¡æœ‰æ–‡ç« æˆ–è€…åªæœ‰ä¸€ç¯‡æ–‡ç« ï¼Œç›´æ¥è¿”å›ï¼Œå‡ºç°è¿™ç§æƒ…å†µçš„åŸå› å¯èƒ½æ˜¯å†·å¯åŠ¨å¬å›çš„æ–‡ç« æ•°é‡å¤ªå°‘äº†ï¼Œ
        # åŸºäºè§„åˆ™ç­›é€‰ä¹‹åå°±æ²¡æœ‰æ–‡ç« äº†, è¿™é‡Œè¿˜å¯ä»¥åšä¸€äº›å…¶ä»–çš„ç­–ç•¥æ€§çš„ç­›é€‰
        if len(sorted_item_list) < 2:
            return sorted_item_list

        min_sim = sorted_item_list[-1][1]
        max_sim = sorted_item_list[0][1]

        norm_sorted_item_list = []
        for item, score in sorted_item_list:
            if max_sim > 0:
                norm_score = 1.0 * (score - min_sim) / (max_sim - min_sim) if max_sim > min_sim else 1.0
            else:
                norm_score = 0.0
            norm_sorted_item_list.append((item, norm_score))

        return norm_sorted_item_list

    print('å¤šè·¯å¬å›åˆå¹¶...')
    for method, user_recall_items in tqdm(user_multi_recall_dict.items(), disable=not logger.isEnabledFor(logging.DEBUG)):
        print(method + '...')
        # åœ¨è®¡ç®—æœ€ç»ˆå¬å›ç»“æœçš„æ—¶å€™ï¼Œä¹Ÿå¯ä»¥ä¸ºæ¯ä¸€ç§å¬å›ç»“æœè®¾ç½®ä¸€ä¸ªæƒé‡
        if weight_dict == None:
            recall_method_weight = 1
        else:
            recall_method_weight = weight_dict[method]

        for user_id, sorted_item_list in user_recall_items.items(): # è¿›è¡Œå½’ä¸€åŒ–
            user_recall_items[user_id] = norm_user_recall_items_sim(sorted_item_list)

        for user_id, sorted_item_list in user_recall_items.items():
            # print('user_id')
            final_recall_items_dict.setdefault(user_id, {})
            for item, score in sorted_item_list:
                final_recall_items_dict[user_id].setdefault(item, 0)
                final_recall_items_dict[user_id][item] += recall_method_weight * score

    final_recall_items_dict_rank = {}
    # å¤šè·¯å¬å›æ—¶ä¹Ÿå¯ä»¥æ§åˆ¶æœ€ç»ˆçš„å¬å›æ•°é‡
    for user, recall_item_dict in final_recall_items_dict.items():
        final_recall_items_dict_rank[user] = sorted(recall_item_dict.items(), key=lambda x: x[1], reverse=True)[:topk]

    # å°†å¤šè·¯å¬å›åçš„æœ€ç»ˆç»“æœå­—å…¸ä¿å­˜åˆ°æœ¬åœ°
    pickle.dump(final_recall_items_dict, open(os.path.join(save_path, 'final_recall_items_dict.pkl'),'wb'))

    return final_recall_items_dict_rank

# Cell 62
# è¿™é‡Œç›´æ¥å¯¹å¤šè·¯å¬å›çš„æƒé‡ç»™äº†ä¸€ä¸ªç›¸åŒçš„å€¼ï¼Œå…¶å®å¯ä»¥æ ¹æ®å‰é¢å¬å›çš„æƒ…å†µæ¥è°ƒæ•´å‚æ•°çš„å€¼
weight_dict = {'itemcf_sim_itemcf_recall': 1.0,
               'embedding_sim_item_recall': 1.0,
               'youtubednn_recall': 1.0,
               'youtubednn_usercf_recall': 1.0,
               'cold_start_recall': 1.0}

# Cell 63
# æœ€ç»ˆåˆå¹¶ä¹‹åæ¯ä¸ªç”¨æˆ·å¬å›150ä¸ªå•†å“è¿›è¡Œæ’åº
final_recall_items_dict_rank = combine_recall_results(user_multi_recall_dict, weight_dict, topk=150)

# Cell 65
# Step 1: å¯¼å…¥å¤šè·¯å¬å›æ¨¡å—
# ç›´æ¥ä»åŒç›®å½•ä¸‹çš„ multi_strategy_recall.py å¯¼å…¥

import sys
sys.path.insert(0, '/Users/ymlin/Library/CloudStorage/OneDrive-Uppsalauniversitet/100-Study/130-CS/136 æœå¹¿æ¨/å¤©æ± æ–°é—»æ¨è/coding')

from multi_strategy_recall import ItemCFRecall, EmbeddingRecall, PopularityRecall, RecallFusion

print("âœ… å¤šè·¯å¬å›æ¨¡å—å¯¼å…¥æˆåŠŸï¼")
print("  - ItemCFRecall: ååŒè¿‡æ»¤å¬å›")
print("  - EmbeddingRecall: å‘é‡æ£€ç´¢å¬å›")
print("  - PopularityRecall: çƒ­é—¨æ¨èå¬å›")
print("  - RecallFusion: å¤šè·¯èåˆç­–ç•¥")

# Cell 66
# Step 2: è®­ç»ƒ ItemCF ååŒè¿‡æ»¤å¬å›
# ä½¿ç”¨å…¨é‡æ•°æ®è®­ç»ƒï¼ˆå› ä¸ºè®¾ç½®äº†offline=Falseï¼‰

print("=" * 60)
print("ğŸ”§ è®­ç»ƒ ItemCF ååŒè¿‡æ»¤å¬å›...")
print("=" * 60)

itemcf_recall = ItemCFRecall(
    sim_item_topk=100,        # æ¯ä¸ªç‰©å“ä¿ç•™top100ç›¸ä¼¼ç‰©å“
    recall_item_number=100    # æ¯ä¸ªç”¨æˆ·å¬å›100ä¸ªå€™é€‰
)

# è®­ç»ƒæ¨¡å‹
itemcf_recall.fit(all_click_df)

print(f"\nâœ… ItemCFè®­ç»ƒå®Œæˆ")
print(f"   - ç‰©å“æ•°é‡: {len(itemcf_recall.item_sim_dict)}")
print(f"   - å¹³å‡ç›¸ä¼¼ç‰©å“æ•°: {np.mean([len(v) for v in itemcf_recall.item_sim_dict.values()]):.1f}")

# Cell 67
# Step 3: è®­ç»ƒ Embedding å‘é‡æ£€ç´¢å¬å›

print("=" * 60)
print("ğŸ”§ è®­ç»ƒ Embedding å‘é‡æ£€ç´¢å¬å›...")
print("=" * 60)

# å‡†å¤‡ embedding æ•°æ®
# ä½¿ç”¨å·²ç»åŠ è½½çš„ item_emb_dictï¼ˆä»ä¹‹å‰çš„cellåŠ è½½ï¼‰
embedding_recall = EmbeddingRecall(
    recall_item_number=100,
    use_faiss=False  # æš‚æ—¶ä¸ç”¨FAISSåŠ é€Ÿï¼Œç›´æ¥è®¡ç®—
)

# éœ€è¦å‡†å¤‡ DataFrame æ ¼å¼çš„ embedding
# ä» item_emb_dict è½¬æ¢ä¸º DataFrame
article_ids = list(item_emb_dict.keys())
embeddings = np.array([item_emb_dict[aid] for aid in article_ids])

# åˆ›å»º embedding DataFrame
emb_dim = embeddings.shape[1]
emb_cols = [f'emb_{i}' for i in range(emb_dim)]
articles_emb_df = pd.DataFrame(embeddings, columns=emb_cols)
articles_emb_df['article_id'] = article_ids

# è®­ç»ƒæ¨¡å‹
embedding_recall.fit(all_click_df, articles_emb_df)

print(f"\nâœ… Embeddingå¬å›è®­ç»ƒå®Œæˆ")
print(f"   - æ–‡ç« æ•°é‡: {len(embedding_recall.item_emb_dict)}")
print(f"   - Embeddingç»´åº¦: {emb_dim}")

# Cell 68
# Step 4: è®­ç»ƒ Popularity çƒ­é—¨æ¨èå¬å›

print("=" * 60)
print("ğŸ”§ è®­ç»ƒ Popularity çƒ­é—¨æ¨èå¬å›...")
print("=" * 60)

popularity_recall = PopularityRecall(
    recall_item_number=100,
    time_decay_factor=0.95  # æ—¶é—´è¡°å‡å› å­ï¼Œè¶Šæ–°çš„æ–‡ç« æƒé‡è¶Šé«˜
)

# è®­ç»ƒæ¨¡å‹
popularity_recall.fit(all_click_df)

print(f"\nâœ… Popularityå¬å›è®­ç»ƒå®Œæˆ")
print(f"   - çƒ­é—¨æ–‡ç« æ•°: {len(popularity_recall.popular_items)}")
print(f"   - Top 5 çƒ­é—¨æ–‡ç« : {popularity_recall.popular_items[:5]}")

# Cell 69
# Step 5: åˆ›å»ºå¤šè·¯å¬å›èåˆ

print("=" * 60)
print("ğŸ¯ åˆ›å»ºå¤šè·¯å¬å›èåˆå™¨...")
print("=" * 60)

# é…ç½®æƒé‡ï¼šæ ¹æ®ç»éªŒå’Œå®éªŒè°ƒæ•´
# ItemCFæ•ˆæœæœ€å¥½ï¼Œç»™æœ€é«˜æƒé‡
# Embeddingå¯¹æ–°æ–‡ç« æ•ˆæœå¥½
# Popularityç”¨äºè¡¥å……å†·å¯åŠ¨
fusion = RecallFusion(
    strategies={
        'itemcf': itemcf_recall,
        'embedding': embedding_recall,
        'popularity': popularity_recall
    },
    weights={
        'itemcf': 0.5,       # ItemCFä¸»åŠ›ï¼Œæƒé‡50%
        'embedding': 0.35,   # Embeddingè¾…åŠ©ï¼Œæƒé‡35%
        'popularity': 0.15   # Popularityå…œåº•ï¼Œæƒé‡15%
    },
    final_topk=150  # æœ€ç»ˆæ¯ä¸ªç”¨æˆ·å¬å›150ä¸ªå€™é€‰ç‰©å“
)

print(f"\nâœ… èåˆå™¨åˆ›å»ºå®Œæˆ")
print(f"   - ç­–ç•¥æ•°é‡: {len(fusion.strategies)}")
print(f"   - èåˆæ–¹æ³•: {fusion.fusion_method}")
print(f"   - æœ€ç»ˆå¬å›æ•°: {fusion.final_topk}")

# Cell 70
# Step 6: ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆå¬å›ç»“æœ

print("=" * 60)
print("ğŸš€ å¼€å§‹æ‰¹é‡å¬å›...")
print("=" * 60)

# è·å–æ‰€æœ‰éœ€è¦å¬å›çš„ç”¨æˆ·
all_users = all_click_df['user_id'].unique()
print(f"æ€»ç”¨æˆ·æ•°: {len(all_users)}")

# ä½¿ç”¨èåˆç­–ç•¥è¿›è¡Œæ‰¹é‡å¬å›
final_recall_results = fusion.predict_batch(all_users, all_click_df)

print(f"\nâœ… å¬å›å®Œæˆ")
print(f"   - å¬å›ç”¨æˆ·æ•°: {len(final_recall_results)}")
print(f"   - å¹³å‡æ¯ç”¨æˆ·å¬å›æ•°: {np.mean([len(items) for items in final_recall_results.values()]):.1f}")

# æ˜¾ç¤ºä¸€ä¸ªç”¨æˆ·çš„å¬å›ç¤ºä¾‹
sample_user = list(final_recall_results.keys())[0]
sample_items = final_recall_results[sample_user]
print(f"\nğŸ“Š ç¤ºä¾‹ç”¨æˆ· {sample_user} çš„å¬å›ç»“æœ:")
print(f"   Top 5 å¬å›: {[item for item, score in sample_items[:5]]}")
print(f"   Top 5 åˆ†æ•°: {[f'{score:.4f}' for item, score in sample_items[:5]]}")

# Cell 71
# Step 7: ç”Ÿæˆæäº¤æ–‡ä»¶

print("=" * 60)
print("ğŸ“ ç”Ÿæˆæäº¤æ–‡ä»¶...")
print("=" * 60)

# åˆ›å»ºæäº¤DataFrame
submission_data = []

for user_id, item_list in final_recall_results.items():
    # å–å‰5ä¸ªæ¨è
    top5_items = [str(item) for item, score in item_list[:5]]
    
    # å¦‚æœä¸è¶³5ä¸ªï¼Œç”¨çƒ­é—¨æ–‡ç« è¡¥è¶³
    while len(top5_items) < 5:
        for pop_item in popularity_recall.popular_items:
            if str(pop_item) not in top5_items:
                top5_items.append(str(pop_item))
                if len(top5_items) == 5:
                    break
    
    submission_data.append({
        'user_id': user_id,
        'article_1': top5_items[0],
        'article_2': top5_items[1],
        'article_3': top5_items[2],
        'article_4': top5_items[3],
        'article_5': top5_items[4]
    })

# åˆ›å»ºDataFrame
submission_df = pd.DataFrame(submission_data)

# ä¿å­˜æ–‡ä»¶
output_file = save_path + 'submission_multi_strategy.csv'
submission_df.to_csv(output_file, index=False)

print(f"\nâœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ")
print(f"   - æ–‡ä»¶è·¯å¾„: {output_file}")
print(f"   - ç”¨æˆ·æ•°: {len(submission_df)}")
print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
print(f"\nğŸ“Š å‰5è¡Œé¢„è§ˆ:")
print(submission_df.head())