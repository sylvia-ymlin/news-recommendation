{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO12AIV4rw2qm/7ENVVr5x1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["充分理解赛题是进行特征工程和模型构建的基础。\n","- 了解赛题概况和数据，分析赛题以及大致的处理方式\n","- 了解模型评测指标\n","# 赛题背景\n","新闻 APP 中新闻推荐，要求根据用户历史浏览数据，预测用户下一次点击的新闻。\n","# 数据概况\n","来自某新闻 APP 的用户交互数据，包括 30 万用户，近 300 万次点击，涉及 36 万篇不同的文章，每个文章有对应的 embedding 向量表示。\n","数据集划分：训练集 20 万，测试集A 5万，测试集B 5万\n","数据表：\n","- *train_click_log.csv*：训练集用户点击日志\n","| 字段名              | 含义         |\n","|---------------------|--------------|\n","| user_id             | 用户id       |\n","| click_article_id    | 点击文章id   |\n","| click_timestamp     | 点击时间戳   |\n","| click_environment   | 点击环境     |\n","| click_deviceGroup   | 点击设备组   |\n","| click_os            | 点击操作系统 |\n","| click_country       | 点击城市     |\n","| click_region        | 点击地区     |\n","| click_referrer_type | 点击来源类型 |\n","\n","- *testA_click_log.csv*：测试集用户点击日志\n","\n","- *articles.csv*: 新闻文章信息数据表\n","| 字段名        | 含义                         |\n","|---------------|------------------------------|\n","| article_id     | 文章id，与 click_article_id 相对应 |\n","| category_id    | 文章类型id                   |\n","| created_at_ts  | 文章创建时间戳               |\n","| words_count    | 文章字数                     |\n","- *articles_emb.csv*：新闻文章embedding向量表示\n","\n","- *sample_submit.csv*：提交样例文件\n","| user_id | article_1 | article_2 | article_3 | article_4 | article_5 |\n","|--------:|----------:|----------:|----------:|----------:|----------:|\n","|  200000 |         1 |         2 |         3 |         4 |         5 |"],"metadata":{"id":"e8e8zkk1djFP"}},{"cell_type":"markdown","source":["# 评价指标\n","根据 *sample_submit.scv*，最后提交的格式，是针对每个用户，给出5篇推荐结果，按照点击的概率从前往后排序。实际每个用户最后一次点击只会是某一篇文章，因为评价指标的公式是\n","$$\\text{score(user)} = \\sum^5_{k=1}\\frac{s(\\text{user}, k)}{k}$$\n","如果五篇推荐结果中，包含用户真实点击的文章，针对该用户得分 $1/k$，$k$ 是这篇文章在推荐结果中的位置。因此排序越靠前，得分越高；如果不在推荐列表中，得分为0.\n"],"metadata":{"id":"UgLOHpa0fLdw"}},{"cell_type":"markdown","source":["# 问题分析\n","目标：根据用户历史点击，预测用户最后一次点击的新闻文章\n","任务类型：看似是推荐，实质是排序 - 需要对候选文章打分，点击概率从高到低。问题在于， 36 万的候选集太大\n","- 召回：将问题看作二元分类{点击，不点击}，筛出候选集 -> 多大？\n","- 精排：把问题当作 CRT 预测，对候选集打分并排序"],"metadata":{"id":"QtTDVSOGgfMk"}},{"cell_type":"markdown","source":["#Baseline"],"metadata":{"id":"10VIPdYaivEO"}},{"cell_type":"code","source":["# import packages\n","import time, math, os\n","from tqdm import tqdm\n","import gc\n","import pickle\n","import random\n","from datetime import datetime\n","from operator import itemgetter\n","import numpy as np\n","import pandas as pd\n","import warnings\n","from collections import defaultdict\n","import collections\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"B2IN97xhiv1l","executionInfo":{"status":"ok","timestamp":1759302164402,"user_tz":-120,"elapsed":533,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43b6890c","executionInfo":{"status":"ok","timestamp":1759302086039,"user_tz":-120,"elapsed":16913,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}},"outputId":"96dabf72-2258-4e3c-81df-59c3a0a7ebb6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/news-recommendation/data/' # 天池平台路径\n","save_path = '/content/drive/MyDrive/news-recommendation/temp_results/'  # 天池平台路径"],"metadata":{"id":"y1YrFqLSky6t","executionInfo":{"status":"ok","timestamp":1759305030995,"user_tz":-120,"elapsed":4,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# df节省内存函数\n","输入：任意一个 pandas.DataFrame\n","\n","输出：同一个 DataFrame，数值列被转成合适的最小数据类型"],"metadata":{"id":"QP31FVV5lMiL"}},{"cell_type":"code","source":["# 节约内存的一个标配函数\n","def reduce_mem(df):\n","    starttime = time.time()\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","\n","    # 计算压缩前内存\n","    start_mem = df.memory_usage().sum() / 1024**2\n","\n","    # 遍历每一列\n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        # 如果是数值类型（int, float), 找到最大最小值，降精度后，在可表示范围内，但是一定会有精度损失\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if pd.isnull(c_min) or pd.isnull(c_max):\n","                continue\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else: # float\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","    # 计算压缩后内存\n","    end_mem = df.memory_usage().sum() / 1024**2\n","\n","    # 输出数据压缩比例和耗时\n","    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,                                                                                                       100*(start_mem-end_mem)/start_mem,\n","                                                                                                           (time.time()-starttime)/60))\n","    return df"],"metadata":{"id":"6Zw1SFR9lJWF","executionInfo":{"status":"ok","timestamp":1759302484299,"user_tz":-120,"elapsed":6,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# 读取采样或全量数据\n","1. 小样本用户调试\n","- 显著降低内存与运行时间，适合“debug 模式”\n","2. 线下/线上两套数据视图\n","- 线下验证只用训练期数据，防止数据泄漏，评估更可信\n","- 线上提交前，把测试点击也并进来，让召回/共现统计覆盖测试期，提高召回质量与覆盖率"],"metadata":{"id":"sjLUjn93mZ88"}},{"cell_type":"code","source":["# debug模式：从训练集中划出一部分数据来调试代码\n","def get_all_click_sample(data_path, sample_nums=10000):\n","    \"\"\"\n","        训练集中采样一部分数据调试\n","        data_path: 原数据的存储路径\n","        sample_nums: 采样数目（这里由于机器的内存限制，可以采样用户做（相对少））\n","    \"\"\"\n","    np.random.seed(42) # 保证复现实验\n","\n","    all_click = pd.read_csv(data_path + \"train_click_log.csv\")\n","    # user_id 去重，拿到所有用户id\n","    all_user_ids = all_click.user_id.unique()\n","\n","    # random.choice: 随机抽取 id，数量 sample_nums, replace=False 表示不放回抽样 -> 不重复 id\n","    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False)\n","    # 获取这些抽样的用户的点击记录\n","    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n","    # 去除重复记录，主要是看 click_timestamp (日志偶尔会重复写入)\n","    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n","\n","    return all_click\n","\n","# 线下 / 线上两种模式的“全量点击日志”，所有用户，非抽样\n","# 线上提交结果：使用所有数据进行训练 train + testA\n","# 线下验证模型：只使用训练集 train\n","def get_all_click_df(data_path, offline=True):\n","    if offline:\n","        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n","    else:\n","        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n","        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n","\n","        # append 在 pandas 2.x 已移除，用 concat\n","        all_click = pd.concat([trn_click, tst_click], ignore_index=True)\n","    # 去重\n","    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n","\n","    return all_click"],"metadata":{"id":"A2we6JehmZXY","executionInfo":{"status":"ok","timestamp":1759305005765,"user_tz":-120,"elapsed":41,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 全量训练集\n","all_click_df = get_all_click_df(data_path, offline=False)"],"metadata":{"id":"EjFti3qXtX8Q","executionInfo":{"status":"ok","timestamp":1759305037813,"user_tz":-120,"elapsed":4551,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# 获取`用户-文章-点击时间`字典\n","为每个用户构造一个按时间升序的**点击序列**，元素是（文章 id，时间戳），便于做序列建模。\n","\n","- 以 user_id 分组，只保留文章ID和时间戳两列。sort=False 表示不改变分组键的顺序，因此每个用户组内的行顺序沿用你在上游对 df 的排序（通常你已经按 click_timestamp 升序排过）\n","- .apply(lambda g: ...)：对每个用户组 g 执行函数\n"," - g['click_article_id'].to_numpy() 和 g['click_timestamp'].to_numpy() 转成 NumPy 数组（比逐行遍历更高效）\n"," - zip(...) 把两列一一配对成 (article_id, timestamp) 元组\n"," - list(...) 实体化为列表\n"," - seq.to_dict()： 把这个 Series 转成 Python 字典"],"metadata":{"id":"76-MtTC-wInY"}},{"cell_type":"code","source":["# 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n","# 传入数据集\n","def get_user_item_time(click_df):\n","    # 按用户+时间戳排序；mergesort 稳定，时间相同不打乱原序\n","    click_df = click_df.sort_values(['user_id', 'click_timestamp'], kind='mergesort')\n","\n","    # 分组后把每个用户的 (item, ts) 序列打包成 list[tuple]\n","    seq = (click_df.groupby('user_id', sort=False)[['click_article_id', 'click_timestamp']]\n","           .apply(lambda g: list(zip(g['click_article_id'].to_numpy(),\n","                                     g['click_timestamp'].to_numpy()))))\n","    return seq.to_dict() # 转换为 字典"],"metadata":{"id":"ACq-XDSwzffe","executionInfo":{"status":"ok","timestamp":1759306414690,"user_tz":-120,"elapsed":7,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# top-k 点击的文章"],"metadata":{"id":"02zM7KYM1S-0"}},{"cell_type":"code","source":["def get_item_topk_click(click_df, k):\n","  # count 文章 id\n","  topk_click = click_df['click_article_id'].value_counts().index[:k]\n","\n","  return topk_click"],"metadata":{"id":"CF6pIamq1V9C","executionInfo":{"status":"ok","timestamp":1759306495498,"user_tz":-120,"elapsed":5,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# ItemCF 计算物品相似度\n","文章与文章之间的相似性矩阵计算\n","- input:\n","  - df 数据表\n","  - item_created_time_dict 文章创建时间的字典\n","- return: 文章和文章的相似性矩阵"],"metadata":{"id":"A2v7TkvIDN-v"}},{"cell_type":"code","source":["def itemcf_sim(df):\n","  # 先获得 用户-文章-时间戳 字典\n","  user_item_time_dict = get_user_item_time(df)\n","\n","  # 计算物品相似度\n","  i2i_sim = {}\n","  item_cnt = defaultdict(int) # 统计物品点击数量\n","\n","  for user, item_time_list in tqdm(user_item_time_dict.items()):\n","    # 对用户的每一次点击\n","    for i, i_click_time in item_time_list:\n","      item_cnt[i] += 1 # 统计文章点击次数\n","      i2i_sim.setdefault(i, {}) # 初始化第 i 个物品\n","      for j, j_click_time in item_time_list:\n","          if(i == j):\n","            continue\n","          # （i， j）初始化\n","          i2i_sim[i].setdefault(j, 0)\n","          # 相似度计算：对用户点击序列里 i,j 共现逐一累加权重，权重是用户点击序列长度\n","          i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n","\n","  i2i_sim_ = i2i_sim.copy()\n","  for i, related_items in i2i_sim.items():\n","      for j, wij in related_items.items():\n","          # 用文章被点击数量做归一化\n","          i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n","\n","  # 将得到的相似性矩阵保存到本地\n","  pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n","\n","  return i2i_sim_"],"metadata":{"id":"qyQlrbigDf3B","executionInfo":{"status":"ok","timestamp":1759310787174,"user_tz":-120,"elapsed":8,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["i2i_sim = itemcf_sim(all_click_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSBvvgebE2HC","executionInfo":{"status":"ok","timestamp":1759310857721,"user_tz":-120,"elapsed":68322,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}},"outputId":"3be9d209-3dcb-477f-b405-e205f1a44cf1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250000/250000 [00:36<00:00, 6903.77it/s]\n"]}]},{"cell_type":"markdown","source":["# 基于 ItemCF 做文章推荐\n","- 从用户历史点击文章出发\n","- 通过 文章-文章 相似度矩阵，找到最相似的候选文章\n","- 累加相似分数，得到候选文章的打分\n","- 如果召回数不足，热门文章做补充\n","- 返回排序后的候选文章列表"],"metadata":{"id":"J1UamXhbGVyk"}},{"cell_type":"code","source":["# 基于 item 做召回 i2i\n","def item_based_recommend(user_id, user_hist_items, i2i_sim, sim_item_topk, recall_item_number, item_topk_click):\n","    # 用户历史交互过的文章\n","    # set，去重后物品\n","    user_hist_items_ = {item_id for item_id, _ in user_hist_items}\n","\n","    item_rank = {} # 候选物品\n","    for loc, (i, click_time) in enumerate(user_hist_items):\n","        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n","            # 去除用户已经浏览过的\n","            for j in user_hist_items_:\n","              continue\n","            item_rank.setdefault(j, 0)\n","            item_rank[j] += wij\n","\n","    if len(item_rank) < recall_item_number:\n","        for i, item in enumerate(item_topk_click):\n","            if item in item_rank.items():\n","                continue\n","            item_rank[item] = - i - 100 # 给负值\n","            if len(item_rank) == recall_item_number:\n","                break\n","\n","    item_rank = sorted(\n","        item_rank.items(),              # 把字典变成 [(item, score), ...] 的列表\n","        key=lambda x: x[1],             # 按元组的第二个元素（score）排序\n","        reverse=True                    # 倒序 → 分数高的在前\n","    )[:recall_item_number]              # 只保留前K个\n","\n","    return item_rank"],"metadata":{"id":"y62ti_ADGtrA","executionInfo":{"status":"ok","timestamp":1759311885987,"user_tz":-120,"elapsed":5,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# 给每个用户根据 ItemCF 推荐文章\n","user_recall_items_dict = collections.defaultdict(dict)\n","\n","user_item_time_dict = get_user_item_time(all_click_df)\n","\n","i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n","\n","sim_item_topk = 10 # 每篇文章选取相似文章数量\n","\n","recall_item_num = 10 # 召回文章数量\n","\n","item_topk_click = get_item_topk_click(all_click_df, k=50) # 热门文章数量\n","\n","for user in tqdm(all_click_df['user_id'].unique()): # 遍历所有用户\n","    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict[user],\n","                                                        i2i_sim, sim_item_topk, recall_item_num,\n","                                                        item_topk_click)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxv5N1omIvTd","executionInfo":{"status":"ok","timestamp":1759315838509,"user_tz":-120,"elapsed":3950672,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}},"outputId":"2bb1f21b-6f4d-4cad-e824-e4d06b8cc139"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250000/250000 [1:05:23<00:00, 63.72it/s]\n"]}]},{"cell_type":"code","source":["# 召回的字典转换为 df\n","user_item_score_list = []\n","\n","for user, items in tqdm(user_recall_items_dict.items()):\n","    for item, score in items:\n","        user_item_score_list.append([user, item, score])\n","\n","recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BHBPKQrKF1i","executionInfo":{"status":"ok","timestamp":1759316051137,"user_tz":-120,"elapsed":9752,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}},"outputId":"f0d8ea4e-ea7b-4837-ea4a-ae7ba4f25f30"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250000/250000 [00:07<00:00, 34621.39it/s]\n"]}]},{"cell_type":"markdown","source":["# 生成提交文件\n"],"metadata":{"id":"BGGAxmYxKdEB"}},{"cell_type":"code","source":["def submit(recall_df, topk=5, model_name=None):\n","    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n","    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n","\n","    # 删除分数列\n","    del recall_df['pred_score']\n","    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n","\n","    # 设置列名\n","    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n","    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2',\n","                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n","\n","    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n","    submit.to_csv(save_name, index=False, header=True)"],"metadata":{"id":"vMbelz5-Kf4t","executionInfo":{"status":"ok","timestamp":1759316068123,"user_tz":-120,"elapsed":7,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# 获取测试集\n","tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n","tst_users = tst_click['user_id'].unique()\n","\n","# 从所有的召回数据中将测试集中的用户选出来\n","# 用的是全量训练集，所以包含 testA 中的用户数据\n","tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n","\n","# 生成提交文件\n","submit(tst_recall, topk=5, model_name='itemcf_baseline')\n"],"metadata":{"id":"RrfPGxsbLgSF","executionInfo":{"status":"ok","timestamp":1759316070778,"user_tz":-120,"elapsed":1236,"user":{"displayName":"Yangmei Lin","userId":"03958463100219057182"}}},"execution_count":24,"outputs":[]}]}